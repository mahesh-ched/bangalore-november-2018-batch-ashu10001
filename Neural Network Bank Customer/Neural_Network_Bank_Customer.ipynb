{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset\n",
    "\n",
    "Drop the columns which are unique for all users like IDs (2.5 points)\n",
    "Distinguish the feature and target set (2.5 points)\n",
    " Divide the data set into Train and test sets\n",
    "Normalize the train and test data (2.5 points)\n",
    " Initialize & build the model (10 points)\n",
    "Optimize the model (5 points)\n",
    "Predict the results using 0.5 as a threshold (5 points)\n",
    " Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns which are unique for all users like IDs (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"RowNumber\", \"CustomerId\",\"Surname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df,columns=[\"Geography\",\"Gender\"], prefix=[\"Geography_\",\"Gender_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography__France</th>\n",
       "      <th>Geography__Germany</th>\n",
       "      <th>Geography__Spain</th>\n",
       "      <th>Gender__Female</th>\n",
       "      <th>Gender__Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography__France  \\\n",
       "0               1        101348.88       1                  1   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  1   \n",
       "3               0         93826.63       0                  1   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography__Germany  Geography__Spain  Gender__Female  Gender__Male  \n",
       "0                   0                 0               1             0  \n",
       "1                   0                 1               1             0  \n",
       "2                   0                 0               1             0  \n",
       "3                   0                 0               1             0  \n",
       "4                   0                 1               1             0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = array(data)\n",
    "# print(data)\n",
    "# # one hot encode\n",
    "# encoded = to_categorical(data)\n",
    "# print(encoded)\n",
    "# # invert encoding\n",
    "# inverted = argmax(encoded[0])\n",
    "# print(inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distinguish the feature and target set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(columns=\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Divide the data set into Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 13)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 13)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the train and test data\n",
    "\n",
    " Initialize & build the model (10 points)\n",
    "Optimize the model (5 points)\n",
    "Predict the results using 0.5 as a threshold (5 points)\n",
    " Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "# model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, input_shape = (13,)))\n",
    "\n",
    "#Normalize the data \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "#Comile the model ((We will learn about optimizers it in the next residency))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "7000/7000 [==============================] - 1s 84us/sample - loss: 0.5635 - acc: 0.7577 - val_loss: 0.5156 - val_acc: 0.7920\n",
      "Epoch 2/50\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.5011 - acc: 0.7981 - val_loss: 0.5033 - val_acc: 0.7920\n",
      "Epoch 3/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 4/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 5/50\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.4980 - acc: 0.7981 - val_loss: 0.5031 - val_acc: 0.7920\n",
      "Epoch 6/50\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.4978 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 7/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 8/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 9/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 10/50\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 11/50\n",
      "7000/7000 [==============================] - 0s 38us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 12/50\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 13/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 14/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 15/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5043 - val_acc: 0.7920\n",
      "Epoch 16/50\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 17/50\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 18/50\n",
      "7000/7000 [==============================] - 0s 49us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5046 - val_acc: 0.7920\n",
      "Epoch 19/50\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 20/50\n",
      "7000/7000 [==============================] - 0s 38us/sample - loss: 0.4980 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 21/50\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 22/50\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5050 - val_acc: 0.7920\n",
      "Epoch 23/50\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5039 - val_acc: 0.7920\n",
      "Epoch 24/50\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4980 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 25/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5036 - val_acc: 0.7920\n",
      "Epoch 26/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 27/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5049 - val_acc: 0.7920\n",
      "Epoch 28/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 29/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 30/50\n",
      "7000/7000 [==============================] - 0s 38us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 31/50\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5034 - val_acc: 0.7920\n",
      "Epoch 32/50\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4978 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 33/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 34/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 35/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 36/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 37/50\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 38/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 39/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 40/50\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 41/50\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 42/50\n",
      "7000/7000 [==============================] - 0s 40us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 43/50\n",
      "7000/7000 [==============================] - 0s 38us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5048 - val_acc: 0.7920\n",
      "Epoch 44/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 45/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5031 - val_acc: 0.7920\n",
      "Epoch 46/50\n",
      "7000/7000 [==============================] - 0s 38us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 47/50\n",
      "7000/7000 [==============================] - 0s 39us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5034 - val_acc: 0.7920\n",
      "Epoch 48/50\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 49/50\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 50/50\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2dec0048>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 22us/sample - loss: 0.5023 - acc: 0.7920\n",
      "Score for model1 is 79.19999957084656\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores1 = model.evaluate(X_test, y_test)\n",
    "# scores2 = model2.evaluate(testX, testY2)\n",
    "# scores3 = model3.evaluate(testX, testY2)\n",
    "\n",
    "\n",
    "print(\"Score for model1 is {}\".format(scores1[1]*100))\n",
    "# print(\"Score for model2 is {}\".format(scores2[1]*100))\n",
    "# print(\"Score for model3 is {}\".format(scores3[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "# model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(10, input_shape = (13,)))\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(20, activation = 'relu'))\n",
    "\n",
    "#Normalize the data \n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model2.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "#Comile the model ((We will learn about optimizers it in the next residency))\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "7000/7000 [==============================] - 1s 94us/sample - loss: 0.5708 - acc: 0.7457 - val_loss: 0.5545 - val_acc: 0.7787\n",
      "Epoch 2/50\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.5003 - acc: 0.7981 - val_loss: 0.5045 - val_acc: 0.7920\n",
      "Epoch 3/50\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 4/50\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4979 - acc: 0.7981 - val_loss: 0.5042 - val_acc: 0.7920\n",
      "Epoch 5/50\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5034 - val_acc: 0.7920\n",
      "Epoch 6/50\n",
      "7000/7000 [==============================] - 0s 59us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5051 - val_acc: 0.7920\n",
      "Epoch 7/50\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4983 - acc: 0.7979 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 8/50\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4978 - acc: 0.7981 - val_loss: 0.5031 - val_acc: 0.7920\n",
      "Epoch 9/50\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 10/50\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4980 - acc: 0.7980 - val_loss: 0.5070 - val_acc: 0.7920\n",
      "Epoch 11/50\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 12/50\n",
      "7000/7000 [==============================] - 0s 49us/sample - loss: 0.4979 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 13/50\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5029 - val_acc: 0.7920\n",
      "Epoch 14/50\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4973 - acc: 0.7980 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 15/50\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5063 - val_acc: 0.7920\n",
      "Epoch 16/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5036 - val_acc: 0.7920\n",
      "Epoch 17/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 18/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5041 - val_acc: 0.7920\n",
      "Epoch 19/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.5024 - acc: 0.7973 - val_loss: 0.5073 - val_acc: 0.7920\n",
      "Epoch 20/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4983 - acc: 0.7981 - val_loss: 0.5038 - val_acc: 0.7920\n",
      "Epoch 21/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4974 - acc: 0.7984 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 22/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4993 - acc: 0.7974 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 23/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 24/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.5027 - acc: 0.7940 - val_loss: 0.5301 - val_acc: 0.7623\n",
      "Epoch 25/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4986 - acc: 0.7977 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 26/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4980 - acc: 0.7980 - val_loss: 0.5087 - val_acc: 0.7920\n",
      "Epoch 27/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4988 - acc: 0.7980 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 28/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5033 - val_acc: 0.7920\n",
      "Epoch 29/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.5023 - acc: 0.7981 - val_loss: 0.5102 - val_acc: 0.7920\n",
      "Epoch 30/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4979 - acc: 0.7981 - val_loss: 0.5015 - val_acc: 0.7920\n",
      "Epoch 31/50\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5060 - val_acc: 0.7920\n",
      "Epoch 32/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4983 - acc: 0.7981 - val_loss: 0.5031 - val_acc: 0.7920\n",
      "Epoch 33/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 34/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5037 - val_acc: 0.7920\n",
      "Epoch 35/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 36/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 37/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 38/50\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 39/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 40/50\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4977 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 41/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 42/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 43/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4978 - acc: 0.7981 - val_loss: 0.5087 - val_acc: 0.7920\n",
      "Epoch 44/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 45/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 46/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 47/50\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 48/50\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 49/50\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 50/50\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2ec7ba58>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 27us/sample - loss: 0.5019 - acc: 0.7920\n",
      "Score for model2 is 79.19999957084656\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# scores1 = model.evaluate(X_test, y_test)\n",
    "scores2 = model2.evaluate(X_test, y_test)\n",
    "# scores3 = model3.evaluate(testX, testY2)\n",
    "\n",
    "\n",
    "# print(\"Score for model1 is {}\".format(scores1[1]*100))\n",
    "print(\"Score for model2 is {}\".format(scores2[1]*100))\n",
    "# print(\"Score for model3 is {}\".format(scores3[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/500\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 2/500\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 3/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 4/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 5/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 6/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 7/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 8/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5033 - val_acc: 0.7920\n",
      "Epoch 9/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 10/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 11/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 12/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 13/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 14/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 15/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 16/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 17/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 18/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 19/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 20/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 21/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 22/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 23/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 24/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 25/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 26/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 27/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 28/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 29/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 30/500\n",
      "7000/7000 [==============================] - 0s 41us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 31/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 32/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 33/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 34/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 35/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 36/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 37/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 38/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5029 - val_acc: 0.7920\n",
      "Epoch 39/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 40/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 41/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 42/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 43/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 44/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 45/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 46/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 47/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 48/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 49/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 50/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 51/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 52/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 53/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 54/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 55/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 56/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 57/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 58/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 60/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5032 - val_acc: 0.7920\n",
      "Epoch 61/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 62/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 63/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 64/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 65/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 66/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 67/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5033 - val_acc: 0.7920\n",
      "Epoch 68/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 69/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 70/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 71/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 72/500\n",
      "7000/7000 [==============================] - 0s 49us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 73/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 74/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 75/500\n",
      "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 76/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 77/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 78/500\n",
      "7000/7000 [==============================] - 0s 56us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 79/500\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 80/500\n",
      "7000/7000 [==============================] - 0s 54us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 81/500\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 82/500\n",
      "7000/7000 [==============================] - 0s 49us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 83/500\n",
      "7000/7000 [==============================] - 0s 58us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 84/500\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 85/500\n",
      "7000/7000 [==============================] - 0s 50us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 86/500\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 87/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 88/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 89/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 90/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 91/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 92/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 93/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 94/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 95/500\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 96/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 97/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5034 - val_acc: 0.7920\n",
      "Epoch 98/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 99/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 100/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 101/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 102/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 103/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5033 - val_acc: 0.7920\n",
      "Epoch 104/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 105/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 106/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 107/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 108/500\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 109/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 110/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 111/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 112/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 113/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 114/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 115/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 116/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 117/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 119/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 120/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 121/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 122/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 123/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 124/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 125/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 126/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5016 - val_acc: 0.7920\n",
      "Epoch 127/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 128/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 129/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 130/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 131/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 132/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 133/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 134/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 135/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 136/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 137/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 138/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 139/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 140/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 141/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 142/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 143/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 144/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 145/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 146/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5029 - val_acc: 0.7920\n",
      "Epoch 147/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 148/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 149/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 150/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 151/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 152/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 153/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 154/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 155/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 156/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 157/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 158/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 159/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 160/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 161/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 162/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 163/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5016 - val_acc: 0.7920\n",
      "Epoch 164/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 165/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 166/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 167/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 168/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 169/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 170/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 171/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5031 - val_acc: 0.7920\n",
      "Epoch 172/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 173/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 174/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 175/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5016 - val_acc: 0.7920\n",
      "Epoch 177/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 178/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 179/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 180/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 181/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 182/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 183/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 184/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 185/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 186/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 187/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 188/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 189/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 190/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 191/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 192/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 193/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 194/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 195/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 196/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 197/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 198/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 199/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 200/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 201/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 202/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 203/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 204/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 205/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 206/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 207/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 208/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 209/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 210/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 211/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5036 - val_acc: 0.7920\n",
      "Epoch 212/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 213/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 214/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 215/500\n",
      "7000/7000 [==============================] - 0s 48us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 216/500\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 217/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 218/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 219/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 220/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 221/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 222/500\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 223/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 224/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 225/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 226/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 227/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 228/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 229/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 230/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 231/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 232/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 233/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 235/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 236/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 237/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 238/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 239/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 240/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 241/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 242/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 243/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 244/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 245/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 246/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 247/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 248/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 249/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 250/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 251/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 252/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 253/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 254/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 255/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4962 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 256/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 257/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 258/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 259/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 260/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 261/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 262/500\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 263/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 264/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 265/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 266/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 267/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 268/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 269/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 270/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 271/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 272/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 273/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 274/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 275/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 276/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 277/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 278/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 279/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 280/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 281/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 282/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 283/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 284/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 285/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 286/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 287/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 288/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 289/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 290/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 291/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 293/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 294/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 295/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 296/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 297/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 298/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 299/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 300/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 301/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 302/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 303/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 304/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 305/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 306/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 307/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 308/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 309/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 310/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4963 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 311/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5016 - val_acc: 0.7920\n",
      "Epoch 312/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 313/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 314/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 315/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5016 - val_acc: 0.7920\n",
      "Epoch 316/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 317/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 318/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 319/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4962 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 320/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 321/500\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 322/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 323/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 324/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 325/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 326/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 327/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 328/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 329/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 330/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 331/500\n",
      "7000/7000 [==============================] - 0s 47us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 332/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 333/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 334/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 335/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 336/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 337/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 338/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 339/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 340/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 341/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 342/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 343/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 344/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 345/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 346/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 347/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 348/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 349/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 351/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 352/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 353/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 354/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 355/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 356/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 357/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 358/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 359/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 360/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 361/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 362/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 363/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4963 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 364/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 365/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 366/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 367/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 368/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 369/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 370/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 371/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 372/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 373/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 374/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 375/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 376/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 377/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 378/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 379/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 380/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 381/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 382/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 383/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 384/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 385/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 386/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 387/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 388/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5029 - val_acc: 0.7920\n",
      "Epoch 389/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 390/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 391/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 392/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 393/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 394/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 395/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 396/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 397/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 398/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 399/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 400/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 401/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4962 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 402/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 403/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 404/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 405/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 406/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 407/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.7920\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 409/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 410/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 411/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 412/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 413/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 414/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4975 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 415/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 416/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 417/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 418/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 419/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 420/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 421/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 422/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 423/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 424/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 425/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 426/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 427/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 428/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5016 - val_acc: 0.7920\n",
      "Epoch 429/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 430/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 431/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 432/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 433/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 434/500\n",
      "7000/7000 [==============================] - 0s 42us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 435/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 436/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4963 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 437/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4976 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 438/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 439/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 440/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 441/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 442/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 443/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 444/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 445/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4964 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 446/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 447/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 448/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 449/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 450/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 451/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 452/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 453/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 454/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 455/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 456/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 457/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 458/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 459/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 460/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5027 - val_acc: 0.7920\n",
      "Epoch 461/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 462/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 463/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 464/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 465/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 467/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 468/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 469/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 470/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5025 - val_acc: 0.7920\n",
      "Epoch 471/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 472/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5024 - val_acc: 0.7920\n",
      "Epoch 473/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 474/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 475/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4963 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 476/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5026 - val_acc: 0.7920\n",
      "Epoch 477/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 478/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 479/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 480/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 481/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 482/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 483/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 484/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 485/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4962 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 486/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 487/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5017 - val_acc: 0.7920\n",
      "Epoch 488/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 489/500\n",
      "7000/7000 [==============================] - 0s 43us/sample - loss: 0.4966 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 490/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4971 - acc: 0.7981 - val_loss: 0.5019 - val_acc: 0.7920\n",
      "Epoch 491/500\n",
      "7000/7000 [==============================] - 0s 44us/sample - loss: 0.4973 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 492/500\n",
      "7000/7000 [==============================] - 0s 46us/sample - loss: 0.4968 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 493/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4974 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 494/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.7920\n",
      "Epoch 495/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5023 - val_acc: 0.7920\n",
      "Epoch 496/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4969 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.7920\n",
      "Epoch 497/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4970 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n",
      "Epoch 498/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4967 - acc: 0.7981 - val_loss: 0.5018 - val_acc: 0.7920\n",
      "Epoch 499/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4965 - acc: 0.7981 - val_loss: 0.5022 - val_acc: 0.7920\n",
      "Epoch 500/500\n",
      "7000/7000 [==============================] - 0s 45us/sample - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.7920\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=32)\n",
    "pyplot.plot(history.history['acc'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(X_test, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7697016  0.23029843]\n",
      "[0.85045904 0.14954104]\n",
      "[0.8471605  0.15283945]\n",
      "[0.77091056 0.22908941]\n",
      "[0.737506   0.26249406]\n",
      "[0.857911   0.14208905]\n",
      "[0.7636635  0.23633653]\n",
      "[0.8510565  0.14894347]\n",
      "[0.85666156 0.14333843]\n",
      "[0.84956354 0.15043645]\n",
      "[0.75817204 0.24182792]\n",
      "[0.78725433 0.21274567]\n",
      "[0.85536385 0.1446361 ]\n",
      "[0.8588684 0.1411316]\n",
      "[0.80343074 0.19656928]\n",
      "[0.7631996  0.23680033]\n",
      "[0.7558995  0.24410056]\n",
      "[0.75745064 0.24254934]\n",
      "[0.76734275 0.23265718]\n",
      "[0.78532696 0.21467309]\n",
      "[0.757397   0.24260302]\n",
      "[0.76258725 0.23741266]\n",
      "[0.7712121  0.22878793]\n",
      "[0.8530142 0.1469858]\n",
      "[0.74700785 0.25299218]\n",
      "[0.8546887  0.14531134]\n",
      "[0.847832  0.1521679]\n",
      "[0.8498104  0.15018952]\n",
      "[0.79792684 0.20207317]\n",
      "[0.861552   0.13844803]\n",
      "[0.79057074 0.20942923]\n",
      "[0.84946847 0.15053155]\n",
      "[0.84861034 0.15138972]\n",
      "[0.856895   0.14310497]\n",
      "[0.7580424  0.24195755]\n",
      "[0.76733035 0.23266968]\n",
      "[0.7253343  0.27466568]\n",
      "[0.7849416  0.21505842]\n",
      "[0.7735307  0.22646934]\n",
      "[0.7306493  0.26935068]\n",
      "[0.85731643 0.14268355]\n",
      "[0.8546627  0.14533725]\n",
      "[0.7892314  0.21076855]\n",
      "[0.86004823 0.1399517 ]\n",
      "[0.86137074 0.13862921]\n",
      "[0.7740624 0.2259376]\n",
      "[0.7724938  0.22750622]\n",
      "[0.7615694  0.23843065]\n",
      "[0.85237956 0.14762047]\n",
      "[0.8504251 0.1495749]\n",
      "[0.8530433  0.14695673]\n",
      "[0.77309984 0.2269002 ]\n",
      "[0.7588866 0.2411134]\n",
      "[0.7673126  0.23268741]\n",
      "[0.85572577 0.14427426]\n",
      "[0.8587373  0.14126267]\n",
      "[0.7412426 0.2587574]\n",
      "[0.85570717 0.14429277]\n",
      "[0.8619442  0.13805577]\n",
      "[0.85481244 0.14518754]\n",
      "[0.8498863  0.15011373]\n",
      "[0.8564782  0.14352177]\n",
      "[0.7699728  0.23002723]\n",
      "[0.8509956 0.1490044]\n",
      "[0.86124223 0.1387578 ]\n",
      "[0.86155945 0.1384405 ]\n",
      "[0.8527869  0.14721307]\n",
      "[0.8517934  0.14820664]\n",
      "[0.85553396 0.14446604]\n",
      "[0.69418216 0.30581787]\n",
      "[0.85689545 0.14310452]\n",
      "[0.7417863  0.25821373]\n",
      "[0.7859046 0.2140954]\n",
      "[0.8593454  0.14065462]\n",
      "[0.8560508  0.14394914]\n",
      "[0.7615493  0.23845069]\n",
      "[0.76338583 0.23661414]\n",
      "[0.85041094 0.14958906]\n",
      "[0.7492634 0.2507365]\n",
      "[0.74473757 0.25526243]\n",
      "[0.74047637 0.25952357]\n",
      "[0.8474295  0.15257052]\n",
      "[0.8577327  0.14226727]\n",
      "[0.7047183  0.29528168]\n",
      "[0.8544394  0.14556067]\n",
      "[0.76296896 0.23703106]\n",
      "[0.85156107 0.1484389 ]\n",
      "[0.7383628  0.26163724]\n",
      "[0.7084442  0.29155588]\n",
      "[0.73535436 0.2646456 ]\n",
      "[0.85666645 0.1433336 ]\n",
      "[0.85925275 0.14074723]\n",
      "[0.8477819  0.15221803]\n",
      "[0.78371996 0.21628003]\n",
      "[0.7549229  0.24507701]\n",
      "[0.857033   0.14296705]\n",
      "[0.77690065 0.22309937]\n",
      "[0.8620277  0.13797231]\n",
      "[0.77441037 0.2255897 ]\n",
      "[0.72631526 0.2736847 ]\n",
      "[0.85032517 0.1496749 ]\n",
      "[0.8565955  0.14340453]\n",
      "[0.8093137  0.19068632]\n",
      "[0.78241104 0.21758899]\n",
      "[0.78633064 0.21366945]\n",
      "[0.73999834 0.2600017 ]\n",
      "[0.8504741  0.14952588]\n",
      "[0.85897964 0.14102037]\n",
      "[0.8591245 0.1408755]\n",
      "[0.75329196 0.2467081 ]\n",
      "[0.7707342  0.22926582]\n",
      "[0.8501196  0.14988044]\n",
      "[0.7209862  0.27901375]\n",
      "[0.7517989  0.24820104]\n",
      "[0.8606248  0.13937522]\n",
      "[0.7534512  0.24654882]\n",
      "[0.74580896 0.254191  ]\n",
      "[0.78056157 0.21943837]\n",
      "[0.7452631  0.25473687]\n",
      "[0.8568432  0.14315681]\n",
      "[0.84915656 0.15084341]\n",
      "[0.74512607 0.2548739 ]\n",
      "[0.79759187 0.20240812]\n",
      "[0.77913743 0.22086263]\n",
      "[0.8546784  0.14532158]\n",
      "[0.7648124  0.23518759]\n",
      "[0.74038666 0.25961336]\n",
      "[0.78636646 0.21363357]\n",
      "[0.77611786 0.22388217]\n",
      "[0.75855255 0.24144746]\n",
      "[0.7998815  0.20011844]\n",
      "[0.75403666 0.2459634 ]\n",
      "[0.8584038  0.14159617]\n",
      "[0.85456914 0.1454309 ]\n",
      "[0.7817954  0.21820459]\n",
      "[0.76137745 0.23862253]\n",
      "[0.8492894  0.15071066]\n",
      "[0.77300787 0.2269921 ]\n",
      "[0.73374265 0.26625735]\n",
      "[0.85790247 0.1420975 ]\n",
      "[0.7642396  0.23576038]\n",
      "[0.7343988 0.2656012]\n",
      "[0.84752196 0.15247805]\n",
      "[0.7846087  0.21539131]\n",
      "[0.75489616 0.2451038 ]\n",
      "[0.7673395  0.23266044]\n",
      "[0.84963864 0.15036136]\n",
      "[0.78229123 0.2177088 ]\n",
      "[0.8478474  0.15215261]\n",
      "[0.7407169  0.25928319]\n",
      "[0.76034814 0.23965178]\n",
      "[0.75631905 0.24368095]\n",
      "[0.78551376 0.2144863 ]\n",
      "[0.7609807  0.23901926]\n",
      "[0.85243106 0.14756888]\n",
      "[0.7789233 0.2210767]\n",
      "[0.84936595 0.15063402]\n",
      "[0.7431701  0.25682992]\n",
      "[0.8565415  0.14345841]\n",
      "[0.7625238  0.23747617]\n",
      "[0.8526199  0.14738008]\n",
      "[0.859276   0.14072405]\n",
      "[0.8593781  0.14062187]\n",
      "[0.8488277  0.15117227]\n",
      "[0.85344535 0.14655462]\n",
      "[0.78538764 0.2146124 ]\n",
      "[0.847331   0.15266903]\n",
      "[0.8540633 0.1459367]\n",
      "[0.8614265  0.13857351]\n",
      "[0.777879   0.22212107]\n",
      "[0.7847974  0.21520266]\n",
      "[0.8530409 0.1469591]\n",
      "[0.84906423 0.15093571]\n",
      "[0.85999984 0.1400001 ]\n",
      "[0.74095917 0.25904083]\n",
      "[0.74770296 0.25229704]\n",
      "[0.75975466 0.2402453 ]\n",
      "[0.72822326 0.2717767 ]\n",
      "[0.85267204 0.14732793]\n",
      "[0.76130587 0.23869412]\n",
      "[0.8610549  0.13894506]\n",
      "[0.7436837 0.2563163]\n",
      "[0.7802308  0.21976915]\n",
      "[0.7510423  0.24895772]\n",
      "[0.74489784 0.25510222]\n",
      "[0.76394725 0.23605275]\n",
      "[0.7903809  0.20961906]\n",
      "[0.7845009  0.21549906]\n",
      "[0.7606887  0.23931128]\n",
      "[0.8283071  0.17169294]\n",
      "[0.7557668  0.24423324]\n",
      "[0.86188275 0.1381173 ]\n",
      "[0.757985   0.24201503]\n",
      "[0.73999065 0.26000932]\n",
      "[0.751047   0.24895298]\n",
      "[0.8471718  0.15282819]\n",
      "[0.8610056  0.13899438]\n",
      "[0.8535551  0.14644493]\n",
      "[0.7887539 0.211246 ]\n",
      "[0.7820141  0.21798593]\n",
      "[0.7970284  0.20297155]\n",
      "[0.8511517  0.14884835]\n",
      "[0.8545309  0.14546919]\n",
      "[0.85917115 0.14082879]\n",
      "[0.7972854  0.20271465]\n",
      "[0.72264546 0.27735454]\n",
      "[0.78155047 0.21844953]\n",
      "[0.7620812  0.23791878]\n",
      "[0.80030537 0.19969466]\n",
      "[0.7646125  0.23538749]\n",
      "[0.7830009  0.21699916]\n",
      "[0.86047524 0.13952474]\n",
      "[0.7599951  0.24000485]\n",
      "[0.857603   0.14239696]\n",
      "[0.75445384 0.24554613]\n",
      "[0.7211581  0.27884197]\n",
      "[0.86179614 0.1382039 ]\n",
      "[0.7782254  0.22177455]\n",
      "[0.7766699  0.22333014]\n",
      "[0.8036451 0.1963549]\n",
      "[0.853514   0.14648601]\n",
      "[0.7799268  0.22007316]\n",
      "[0.76993966 0.23006031]\n",
      "[0.802783   0.19721699]\n",
      "[0.8538063  0.14619365]\n",
      "[0.8475408  0.15245917]\n",
      "[0.7671432  0.23285678]\n",
      "[0.8550512  0.14494877]\n",
      "[0.75725466 0.24274534]\n",
      "[0.7704946  0.22950543]\n",
      "[0.77048    0.22951998]\n",
      "[0.7415707  0.25842926]\n",
      "[0.7716865  0.22831348]\n",
      "[0.8484148  0.15158522]\n",
      "[0.8485753  0.15142469]\n",
      "[0.76625025 0.23374976]\n",
      "[0.7732979  0.22670208]\n",
      "[0.8041051  0.19589491]\n",
      "[0.75119996 0.24879998]\n",
      "[0.70237476 0.29762518]\n",
      "[0.7599736  0.24002646]\n",
      "[0.782572   0.21742801]\n",
      "[0.8018829  0.19811706]\n",
      "[0.848811 0.151189]\n",
      "[0.76636356 0.23363638]\n",
      "[0.734232   0.26576796]\n",
      "[0.7439314 0.2560686]\n",
      "[0.8555389 0.1444611]\n",
      "[0.74683595 0.253164  ]\n",
      "[0.7879225  0.21207756]\n",
      "[0.7796746  0.22032541]\n",
      "[0.851464   0.14853603]\n",
      "[0.7852179 0.2147821]\n",
      "[0.77555716 0.22444282]\n",
      "[0.86055654 0.13944344]\n",
      "[0.7484193  0.25158074]\n",
      "[0.7235081  0.27649185]\n",
      "[0.85849077 0.14150918]\n",
      "[0.74963623 0.25036377]\n",
      "[0.76643413 0.23356584]\n",
      "[0.79908514 0.20091486]\n",
      "[0.8481354  0.15186456]\n",
      "[0.8527913  0.14720863]\n",
      "[0.85950035 0.14049968]\n",
      "[0.7633059  0.23669408]\n",
      "[0.7540835  0.24591655]\n",
      "[0.82765216 0.17234784]\n",
      "[0.7635143 0.2364857]\n",
      "[0.79539645 0.20460357]\n",
      "[0.7816535  0.21834645]\n",
      "[0.7694841  0.23051593]\n",
      "[0.76596016 0.23403981]\n",
      "[0.85946757 0.14053239]\n",
      "[0.7679022  0.23209786]\n",
      "[0.76375484 0.23624521]\n",
      "[0.75835913 0.24164088]\n",
      "[0.77366215 0.22633784]\n",
      "[0.86146176 0.13853824]\n",
      "[0.77674 0.22326]\n",
      "[0.8471177  0.15288223]\n",
      "[0.7341401  0.26585984]\n",
      "[0.75084007 0.24915996]\n",
      "[0.75616455 0.24383545]\n",
      "[0.7455121  0.25448787]\n",
      "[0.75118065 0.24881934]\n",
      "[0.85996985 0.14003015]\n",
      "[0.7820331 0.2179669]\n",
      "[0.71924603 0.28075394]\n",
      "[0.7978122 0.2021877]\n",
      "[0.7723426  0.22765741]\n",
      "[0.75281155 0.24718846]\n",
      "[0.7543151 0.2456849]\n",
      "[0.8511564  0.14884351]\n",
      "[0.7609535  0.23904656]\n",
      "[0.78777856 0.21222141]\n",
      "[0.74334735 0.25665265]\n",
      "[0.7444435  0.25555646]\n",
      "[0.7819974  0.21800263]\n",
      "[0.8505688  0.14943118]\n",
      "[0.76929235 0.23070762]\n",
      "[0.78735125 0.21264873]\n",
      "[0.7620561  0.23794384]\n",
      "[0.7510391  0.24896094]\n",
      "[0.86100453 0.13899542]\n",
      "[0.849424   0.15057603]\n",
      "[0.76530904 0.23469101]\n",
      "[0.8565909  0.14340904]\n",
      "[0.7382226  0.26177734]\n",
      "[0.7941005  0.20589949]\n",
      "[0.8614394  0.13856064]\n",
      "[0.8536905  0.14630948]\n",
      "[0.7443999 0.2556001]\n",
      "[0.84874994 0.15125011]\n",
      "[0.8464381  0.15356183]\n",
      "[0.8179252  0.18207482]\n",
      "[0.82015854 0.17984146]\n",
      "[0.7810211  0.21897887]\n",
      "[0.78993714 0.21006289]\n",
      "[0.8609951  0.13900496]\n",
      "[0.8494578  0.15054218]\n",
      "[0.7721086  0.22789137]\n",
      "[0.75692254 0.24307743]\n",
      "[0.77834743 0.22165258]\n",
      "[0.7359802 0.2640198]\n",
      "[0.74799335 0.25200662]\n",
      "[0.72805595 0.27194414]\n",
      "[0.77037066 0.22962932]\n",
      "[0.8589362  0.14106375]\n",
      "[0.775848   0.22415197]\n",
      "[0.84742934 0.1525707 ]\n",
      "[0.74755204 0.25244796]\n",
      "[0.7514017  0.24859826]\n",
      "[0.8591883  0.14081162]\n",
      "[0.7638205  0.23617944]\n",
      "[0.7775418  0.22245821]\n",
      "[0.73610574 0.26389423]\n",
      "[0.86030596 0.13969396]\n",
      "[0.8142453  0.18575476]\n",
      "[0.7597957  0.24020433]\n",
      "[0.7464819  0.25351816]\n",
      "[0.85853094 0.14146905]\n",
      "[0.84805393 0.15194604]\n",
      "[0.74191624 0.2580838 ]\n",
      "[0.79077744 0.20922256]\n",
      "[0.8513881  0.14861181]\n",
      "[0.853659 0.146341]\n",
      "[0.8518496  0.14815041]\n",
      "[0.74616015 0.25383982]\n",
      "[0.7496255 0.2503745]\n",
      "[0.73694825 0.26305175]\n",
      "[0.77163297 0.228367  ]\n",
      "[0.73344326 0.2665567 ]\n",
      "[0.8515524  0.14844757]\n",
      "[0.8483138  0.15168619]\n",
      "[0.85026866 0.14973137]\n",
      "[0.8592592  0.14074084]\n",
      "[0.7384943  0.26150575]\n",
      "[0.75802517 0.24197488]\n",
      "[0.76242787 0.23757218]\n",
      "[0.8499049 0.1500951]\n",
      "[0.7758827  0.22411725]\n",
      "[0.8490492  0.15095082]\n",
      "[0.8020277  0.19797233]\n",
      "[0.7458224  0.25417757]\n",
      "[0.7456759  0.25432405]\n",
      "[0.7314257  0.26857427]\n",
      "[0.80269927 0.1973007 ]\n",
      "[0.8498755  0.15012448]\n",
      "[0.7339322  0.26606777]\n",
      "[0.7129141  0.28708586]\n",
      "[0.77362704 0.22637294]\n",
      "[0.7846098 0.2153902]\n",
      "[0.76846075 0.23153925]\n",
      "[0.852222   0.14777796]\n",
      "[0.7982547  0.20174526]\n",
      "[0.8475516  0.15244839]\n",
      "[0.7448683 0.2551317]\n",
      "[0.77004623 0.22995374]\n",
      "[0.75145906 0.24854095]\n",
      "[0.7814143 0.2185857]\n",
      "[0.85858154 0.1414184 ]\n",
      "[0.72910106 0.2708989 ]\n",
      "[0.80327475 0.19672526]\n",
      "[0.8605015  0.13949849]\n",
      "[0.7716503  0.22834969]\n",
      "[0.80163527 0.1983647 ]\n",
      "[0.8605485  0.13945147]\n",
      "[0.7535075  0.24649252]\n",
      "[0.7573132  0.24268688]\n",
      "[0.73843735 0.2615626 ]\n",
      "[0.77572936 0.22427061]\n",
      "[0.7516203 0.2483797]\n",
      "[0.85921746 0.14078256]\n",
      "[0.8621085  0.13789149]\n",
      "[0.77429724 0.22570269]\n",
      "[0.84757483 0.15242517]\n",
      "[0.7721095  0.22789046]\n",
      "[0.7505355  0.24946453]\n",
      "[0.7471064  0.25289366]\n",
      "[0.76755947 0.23244052]\n",
      "[0.7494847  0.25051528]\n",
      "[0.8568336  0.14316638]\n",
      "[0.77019507 0.22980496]\n",
      "[0.755772   0.24422804]\n",
      "[0.774513   0.22548702]\n",
      "[0.8302398  0.16976026]\n",
      "[0.77640766 0.22359239]\n",
      "[0.6904852  0.30951476]\n",
      "[0.7240252  0.27597475]\n",
      "[0.7844163  0.21558361]\n",
      "[0.7602416  0.23975842]\n",
      "[0.7729282 0.2270718]\n",
      "[0.7665989  0.23340113]\n",
      "[0.75617146 0.24382855]\n",
      "[0.85271233 0.14728765]\n",
      "[0.773089   0.22691093]\n",
      "[0.7458596  0.25414038]\n",
      "[0.7543914  0.24560866]\n",
      "[0.77534664 0.22465336]\n",
      "[0.7950059  0.20499414]\n",
      "[0.85979104 0.14020894]\n",
      "[0.76942974 0.23057027]\n",
      "[0.8501882  0.14981185]\n",
      "[0.7752871  0.22471294]\n",
      "[0.8469419 0.1530581]\n",
      "[0.7801448  0.21985513]\n",
      "[0.8023855  0.19761455]\n",
      "[0.73859346 0.26140645]\n",
      "[0.8312283  0.16877165]\n",
      "[0.8033759  0.19662409]\n",
      "[0.8494039  0.15059601]\n",
      "[0.7617498 0.2382502]\n",
      "[0.8473456  0.15265444]\n",
      "[0.754273   0.24572694]\n",
      "[0.85077494 0.14922503]\n",
      "[0.7734078  0.22659214]\n",
      "[0.8502522 0.1497478]\n",
      "[0.77655286 0.22344716]\n",
      "[0.7793172  0.22068273]\n",
      "[0.7572854  0.24271461]\n",
      "[0.7763864  0.22361362]\n",
      "[0.85416496 0.14583501]\n",
      "[0.79671705 0.20328304]\n",
      "[0.7764504  0.22354957]\n",
      "[0.7841726  0.21582739]\n",
      "[0.76453865 0.2354614 ]\n",
      "[0.84787095 0.15212907]\n",
      "[0.8579763  0.14202371]\n",
      "[0.84707093 0.15292908]\n",
      "[0.7361333  0.26386678]\n",
      "[0.8530187  0.14698131]\n",
      "[0.8587321  0.14126784]\n",
      "[0.785429   0.21457098]\n",
      "[0.7709642  0.22903575]\n",
      "[0.8558758  0.14412427]\n",
      "[0.784521 0.215479]\n",
      "[0.8563246  0.14367543]\n",
      "[0.7555041  0.24449588]\n",
      "[0.84734833 0.15265165]\n",
      "[0.760537   0.23946296]\n",
      "[0.8516114  0.14838864]\n",
      "[0.77524656 0.2247535 ]\n",
      "[0.84873265 0.15126735]\n",
      "[0.7540353  0.24596475]\n",
      "[0.75165254 0.24834743]\n",
      "[0.8484707  0.15152931]\n",
      "[0.8515081  0.14849187]\n",
      "[0.7607431  0.23925695]\n",
      "[0.78509307 0.21490693]\n",
      "[0.7722799  0.22772005]\n",
      "[0.8504749  0.14952514]\n",
      "[0.7579817  0.24201831]\n",
      "[0.86040676 0.13959318]\n",
      "[0.77801263 0.22198732]\n",
      "[0.72338325 0.27661678]\n",
      "[0.78204435 0.21795571]\n",
      "[0.8540501  0.14594993]\n",
      "[0.80428594 0.19571406]\n",
      "[0.78240323 0.21759684]\n",
      "[0.7507422  0.24925782]\n",
      "[0.78726864 0.21273133]\n",
      "[0.7550808 0.2449192]\n",
      "[0.8060732  0.19392677]\n",
      "[0.84651667 0.15348326]\n",
      "[0.7834033  0.21659668]\n",
      "[0.78564703 0.21435297]\n",
      "[0.84793353 0.15206648]\n",
      "[0.85113615 0.14886387]\n",
      "[0.85968673 0.14031331]\n",
      "[0.7786085  0.22139147]\n",
      "[0.79975843 0.20024152]\n",
      "[0.76495016 0.23504983]\n",
      "[0.8580031  0.14199692]\n",
      "[0.84751976 0.15248024]\n",
      "[0.8616254 0.1383746]\n",
      "[0.8576013  0.14239874]\n",
      "[0.72965467 0.27034533]\n",
      "[0.7907442  0.20925578]\n",
      "[0.7673435  0.23265643]\n",
      "[0.74659175 0.2534082 ]\n",
      "[0.7757136 0.2242864]\n",
      "[0.73160625 0.26839378]\n",
      "[0.77162164 0.2283784 ]\n",
      "[0.8026466 0.1973534]\n",
      "[0.7685778  0.23142219]\n",
      "[0.771387   0.22861302]\n",
      "[0.85451823 0.14548181]\n",
      "[0.763447   0.23655301]\n",
      "[0.77819824 0.2218018 ]\n",
      "[0.7441604  0.25583953]\n",
      "[0.8467988  0.15320127]\n",
      "[0.7856209  0.21437909]\n",
      "[0.7570125  0.24298754]\n",
      "[0.7669007  0.23309928]\n",
      "[0.77098155 0.22901838]\n",
      "[0.75034887 0.24965104]\n",
      "[0.7589189  0.24108112]\n",
      "[0.852068   0.14793195]\n",
      "[0.79138595 0.20861405]\n",
      "[0.7766735  0.22332652]\n",
      "[0.76896024 0.23103978]\n",
      "[0.74202585 0.2579742 ]\n",
      "[0.8498906  0.15010941]\n",
      "[0.7647273  0.23527268]\n",
      "[0.7891789  0.21082109]\n",
      "[0.7553664  0.24463367]\n",
      "[0.74470747 0.25529253]\n",
      "[0.7605165  0.23948354]\n",
      "[0.8589963  0.14100376]\n",
      "[0.7773853  0.22261462]\n",
      "[0.8615729  0.13842711]\n",
      "[0.756806 0.243194]\n",
      "[0.8537103 0.1462897]\n",
      "[0.7891949  0.21080509]\n",
      "[0.75984114 0.24015889]\n",
      "[0.7661843  0.23381577]\n",
      "[0.8472525  0.15274754]\n",
      "[0.7823968  0.21760327]\n",
      "[0.76372033 0.2362797 ]\n",
      "[0.7342147  0.26578525]\n",
      "[0.74483085 0.25516915]\n",
      "[0.84815    0.15185001]\n",
      "[0.7276144 0.2723856]\n",
      "[0.77259123 0.22740875]\n",
      "[0.76983863 0.23016144]\n",
      "[0.85875374 0.14124626]\n",
      "[0.8510311  0.14896885]\n",
      "[0.8582315 0.1417685]\n",
      "[0.78780335 0.21219663]\n",
      "[0.84802884 0.15197112]\n",
      "[0.75558037 0.24441962]\n",
      "[0.8545419  0.14545813]\n",
      "[0.77690923 0.2230908 ]\n",
      "[0.74524385 0.25475615]\n",
      "[0.7848454  0.21515465]\n",
      "[0.78655744 0.21344262]\n",
      "[0.7951837  0.20481628]\n",
      "[0.7816712  0.21832879]\n",
      "[0.77266985 0.22733012]\n",
      "[0.8576826  0.14231747]\n",
      "[0.78392625 0.21607383]\n",
      "[0.85462636 0.14537366]\n",
      "[0.85041374 0.14958625]\n",
      "[0.75117207 0.24882798]\n",
      "[0.8599008  0.14009926]\n",
      "[0.8574469  0.14255309]\n",
      "[0.7625085 0.2374915]\n",
      "[0.75632286 0.24367715]\n",
      "[0.7882628  0.21173722]\n",
      "[0.85910976 0.14089026]\n",
      "[0.777278   0.22272196]\n",
      "[0.7528383  0.24716164]\n",
      "[0.8485322 0.1514678]\n",
      "[0.74146587 0.25853416]\n",
      "[0.7264884  0.27351156]\n",
      "[0.85041016 0.14958988]\n",
      "[0.8576547  0.14234531]\n",
      "[0.84966207 0.15033792]\n",
      "[0.75537956 0.2446204 ]\n",
      "[0.784458   0.21554193]\n",
      "[0.75678176 0.24321823]\n",
      "[0.78238326 0.21761672]\n",
      "[0.73578894 0.26421112]\n",
      "[0.79036415 0.20963587]\n",
      "[0.86105394 0.1389461 ]\n",
      "[0.79729    0.20270999]\n",
      "[0.85145    0.14854996]\n",
      "[0.7846838  0.21531624]\n",
      "[0.77472293 0.225277  ]\n",
      "[0.7416503  0.25834975]\n",
      "[0.78367186 0.21632813]\n",
      "[0.7848091  0.21519093]\n",
      "[0.75761527 0.24238472]\n",
      "[0.776366   0.22363408]\n",
      "[0.73086643 0.26913357]\n",
      "[0.8552333  0.14476667]\n",
      "[0.7977054  0.20229457]\n",
      "[0.7757955  0.22420447]\n",
      "[0.8568575  0.14314255]\n",
      "[0.8036554  0.19634458]\n",
      "[0.7652049  0.23479506]\n",
      "[0.84788185 0.15211813]\n",
      "[0.76266396 0.23733604]\n",
      "[0.7346072  0.26539278]\n",
      "[0.7379625 0.2620375]\n",
      "[0.8538169  0.14618301]\n",
      "[0.8543668  0.14563319]\n",
      "[0.74243224 0.2575678 ]\n",
      "[0.85826033 0.14173968]\n",
      "[0.7553207  0.24467923]\n",
      "[0.8572241  0.14277595]\n",
      "[0.7264061 0.2735939]\n",
      "[0.79218996 0.20781001]\n",
      "[0.85779923 0.1422008 ]\n",
      "[0.8021029  0.19789712]\n",
      "[0.7468192  0.25318083]\n",
      "[0.8525183  0.14748168]\n",
      "[0.73059624 0.2694038 ]\n",
      "[0.84763587 0.15236416]\n",
      "[0.77382636 0.22617365]\n",
      "[0.8607389  0.13926105]\n",
      "[0.79595    0.20405002]\n",
      "[0.85733676 0.14266323]\n",
      "[0.78703696 0.21296301]\n",
      "[0.79392093 0.20607913]\n",
      "[0.775156   0.22484398]\n",
      "[0.84730315 0.15269683]\n",
      "[0.756757   0.24324292]\n",
      "[0.85318875 0.14681122]\n",
      "[0.77828306 0.22171697]\n",
      "[0.7706301  0.22936982]\n",
      "[0.7640143  0.23598571]\n",
      "[0.77629334 0.22370666]\n",
      "[0.78595006 0.21404992]\n",
      "[0.75245136 0.24754855]\n",
      "[0.74517024 0.25482973]\n",
      "[0.78777575 0.21222426]\n",
      "[0.8595882  0.14041175]\n",
      "[0.85987467 0.1401253 ]\n",
      "[0.85028964 0.14971037]\n",
      "[0.8477804  0.15221962]\n",
      "[0.8548188  0.14518115]\n",
      "[0.8481606  0.15183938]\n",
      "[0.8521604  0.14783965]\n",
      "[0.7473472  0.25265282]\n",
      "[0.73694074 0.26305932]\n",
      "[0.7830037  0.21699634]\n",
      "[0.8497748  0.15022518]\n",
      "[0.8043582  0.19564185]\n",
      "[0.85040826 0.14959179]\n",
      "[0.7608144  0.23918563]\n",
      "[0.8527919  0.14720808]\n",
      "[0.862074   0.13792595]\n",
      "[0.85106975 0.14893022]\n",
      "[0.7991123  0.20088764]\n",
      "[0.86190635 0.13809367]\n",
      "[0.7785048  0.22149517]\n",
      "[0.81824493 0.1817551 ]\n",
      "[0.8565423  0.14345771]\n",
      "[0.75420755 0.2457924 ]\n",
      "[0.86175567 0.13824435]\n",
      "[0.8584403  0.14155975]\n",
      "[0.84868664 0.1513134 ]\n",
      "[0.78182864 0.2181713 ]\n",
      "[0.8467541  0.15324596]\n",
      "[0.79289865 0.20710133]\n",
      "[0.7917633  0.20823671]\n",
      "[0.85663784 0.14336221]\n",
      "[0.851206   0.14879395]\n",
      "[0.7735163  0.22648372]\n",
      "[0.78455514 0.21544483]\n",
      "[0.80051166 0.19948831]\n",
      "[0.8559469  0.14405312]\n",
      "[0.71557295 0.28442705]\n",
      "[0.74763244 0.2523676 ]\n",
      "[0.7667543  0.23324575]\n",
      "[0.7569026  0.24309747]\n",
      "[0.84770167 0.15229833]\n",
      "[0.77369565 0.22630431]\n",
      "[0.7493154  0.25068465]\n",
      "[0.8615944 0.1384056]\n",
      "[0.85662705 0.14337295]\n",
      "[0.80524343 0.19475661]\n",
      "[0.8559619  0.14403808]\n",
      "[0.741328   0.25867203]\n",
      "[0.84685373 0.15314622]\n",
      "[0.8513302  0.14866973]\n",
      "[0.78083175 0.21916826]\n",
      "[0.8623107  0.13768923]\n",
      "[0.77313685 0.22686316]\n",
      "[0.78527445 0.21472558]\n",
      "[0.7800129  0.21998714]\n",
      "[0.85799897 0.142001  ]\n",
      "[0.8561271  0.14387295]\n",
      "[0.7613423  0.23865773]\n",
      "[0.85131323 0.1486868 ]\n",
      "[0.8475714  0.15242864]\n",
      "[0.8561756  0.14382443]\n",
      "[0.8506839  0.14931606]\n",
      "[0.78142846 0.21857153]\n",
      "[0.8040132  0.19598679]\n",
      "[0.7887193 0.2112807]\n",
      "[0.7934207  0.20657936]\n",
      "[0.8498991  0.15010083]\n",
      "[0.737475   0.26252502]\n",
      "[0.7926846  0.20731536]\n",
      "[0.86011916 0.13988082]\n",
      "[0.75404423 0.2459557 ]\n",
      "[0.75127065 0.24872933]\n",
      "[0.7633685  0.23663156]\n",
      "[0.7681413  0.23185867]\n",
      "[0.78419477 0.21580529]\n",
      "[0.85277796 0.14722204]\n",
      "[0.7660123  0.23398763]\n",
      "[0.7681728  0.23182727]\n",
      "[0.7775366  0.22246341]\n",
      "[0.78048503 0.21951492]\n",
      "[0.854032   0.14596798]\n",
      "[0.7614995  0.23850048]\n",
      "[0.7988579  0.20114207]\n",
      "[0.7841549 0.2158451]\n",
      "[0.7635383 0.2364617]\n",
      "[0.76639944 0.23360063]\n",
      "[0.7900929  0.20990716]\n",
      "[0.7595711  0.24042892]\n",
      "[0.8132996  0.18670034]\n",
      "[0.7313029  0.26869714]\n",
      "[0.77103245 0.22896749]\n",
      "[0.758743   0.24125695]\n",
      "[0.77129376 0.22870627]\n",
      "[0.75256425 0.2474358 ]\n",
      "[0.7978832  0.20211683]\n",
      "[0.85273534 0.1472647 ]\n",
      "[0.75994533 0.2400546 ]\n",
      "[0.7706238  0.22937615]\n",
      "[0.7392347 0.2607653]\n",
      "[0.8530359  0.14696407]\n",
      "[0.7418924  0.25810757]\n",
      "[0.7651152  0.23488486]\n",
      "[0.737079   0.26292092]\n",
      "[0.8486973  0.15130274]\n",
      "[0.7625091  0.23749089]\n",
      "[0.76657534 0.23342465]\n",
      "[0.74213666 0.2578634 ]\n",
      "[0.7605498  0.23945019]\n",
      "[0.8483626  0.15163736]\n",
      "[0.77998704 0.22001293]\n",
      "[0.7827463  0.21725366]\n",
      "[0.7563643  0.24363573]\n",
      "[0.7650116  0.23498835]\n",
      "[0.7651061  0.23489392]\n",
      "[0.8116732  0.18832673]\n",
      "[0.8580558  0.14194421]\n",
      "[0.75750583 0.24249421]\n",
      "[0.7744026  0.22559738]\n",
      "[0.84684193 0.1531581 ]\n",
      "[0.74308836 0.25691164]\n",
      "[0.7827255  0.21727447]\n",
      "[0.8476429  0.15235706]\n",
      "[0.7554071  0.24459285]\n",
      "[0.8532487  0.14675131]\n",
      "[0.86173683 0.13826314]\n",
      "[0.7480348 0.2519652]\n",
      "[0.7751163  0.22488363]\n",
      "[0.7716357  0.22836427]\n",
      "[0.8043227  0.19567725]\n",
      "[0.7575876  0.24241234]\n",
      "[0.7741537  0.22584632]\n",
      "[0.78482467 0.21517535]\n",
      "[0.84716684 0.15283312]\n",
      "[0.84679896 0.15320103]\n",
      "[0.78818494 0.2118151 ]\n",
      "[0.7094316  0.29056838]\n",
      "[0.78649396 0.21350601]\n",
      "[0.8575306  0.14246933]\n",
      "[0.7748471  0.22515284]\n",
      "[0.7828001  0.21719989]\n",
      "[0.7696586  0.23034136]\n",
      "[0.8536707  0.14632927]\n",
      "[0.75790244 0.24209759]\n",
      "[0.84797996 0.15202007]\n",
      "[0.7566948  0.24330516]\n",
      "[0.76739866 0.23260136]\n",
      "[0.765839   0.23416108]\n",
      "[0.7608412  0.23915881]\n",
      "[0.86172265 0.13827741]\n",
      "[0.7726571  0.22734289]\n",
      "[0.78765404 0.21234594]\n",
      "[0.76125956 0.2387405 ]\n",
      "[0.8503423  0.14965765]\n",
      "[0.84983873 0.15016124]\n",
      "[0.743833   0.25616696]\n",
      "[0.7753629  0.22463703]\n",
      "[0.85975426 0.14024574]\n",
      "[0.7697384  0.23026165]\n",
      "[0.85404086 0.14595914]\n",
      "[0.7837506  0.21624945]\n",
      "[0.7888956  0.21110435]\n",
      "[0.8530845  0.14691544]\n",
      "[0.7927703 0.2072297]\n",
      "[0.8584886  0.14151135]\n",
      "[0.7955478  0.20445222]\n",
      "[0.78189886 0.21810119]\n",
      "[0.76469153 0.23530851]\n",
      "[0.8570786 0.1429214]\n",
      "[0.73711735 0.26288262]\n",
      "[0.77596295 0.22403705]\n",
      "[0.8089916  0.19100839]\n",
      "[0.70760727 0.29239267]\n",
      "[0.8478652  0.15213479]\n",
      "[0.75251025 0.24748974]\n",
      "[0.79795223 0.2020477 ]\n",
      "[0.7254667 0.2745333]\n",
      "[0.7896614  0.21033853]\n",
      "[0.855843   0.14415693]\n",
      "[0.7658844  0.23411562]\n",
      "[0.8537065 0.1462935]\n",
      "[0.84962314 0.1503768 ]\n",
      "[0.7620238 0.2379762]\n",
      "[0.85076463 0.1492354 ]\n",
      "[0.79604477 0.20395522]\n",
      "[0.7719847 0.2280153]\n",
      "[0.77979463 0.22020535]\n",
      "[0.7618213  0.23817869]\n",
      "[0.79338485 0.20661516]\n",
      "[0.7911466  0.20885338]\n",
      "[0.7473759  0.25262403]\n",
      "[0.78655136 0.21344866]\n",
      "[0.7240547  0.27594537]\n",
      "[0.77529603 0.22470394]\n",
      "[0.8538767  0.14612325]\n",
      "[0.8573895 0.1426105]\n",
      "[0.79289734 0.20710263]\n",
      "[0.8595452  0.14045484]\n",
      "[0.7531678  0.24683225]\n",
      "[0.8581425 0.1418575]\n",
      "[0.7539709  0.24602911]\n",
      "[0.85346156 0.14653842]\n",
      "[0.8538724  0.14612758]\n",
      "[0.85667413 0.14332585]\n",
      "[0.77839875 0.22160122]\n",
      "[0.768947 0.231053]\n",
      "[0.8496612  0.15033884]\n",
      "[0.7545834  0.24541658]\n",
      "[0.72865975 0.27134025]\n",
      "[0.84872603 0.151274  ]\n",
      "[0.8611617  0.13883832]\n",
      "[0.7523015  0.24769846]\n",
      "[0.7820369  0.21796314]\n",
      "[0.76895285 0.23104718]\n",
      "[0.77812946 0.22187057]\n",
      "[0.856583 0.143417]\n",
      "[0.8504035  0.14959653]\n",
      "[0.75688446 0.24311554]\n",
      "[0.85611624 0.14388375]\n",
      "[0.7793413  0.22065872]\n",
      "[0.7402848 0.2597152]\n",
      "[0.73717827 0.2628217 ]\n",
      "[0.74615794 0.25384212]\n",
      "[0.77111554 0.22888447]\n",
      "[0.8589706 0.1410294]\n",
      "[0.7653937  0.23460636]\n",
      "[0.7684281  0.23157194]\n",
      "[0.7877492  0.21225083]\n",
      "[0.7404898  0.25951022]\n",
      "[0.7980621  0.20193791]\n",
      "[0.75920284 0.24079719]\n",
      "[0.85348386 0.14651607]\n",
      "[0.71204245 0.28795752]\n",
      "[0.8544016 0.1455984]\n",
      "[0.8549472  0.14505276]\n",
      "[0.76760006 0.23240001]\n",
      "[0.846824   0.15317602]\n",
      "[0.79261494 0.20738502]\n",
      "[0.85204244 0.14795762]\n",
      "[0.7868726  0.21312739]\n",
      "[0.8479148  0.15208511]\n",
      "[0.7707344  0.22926556]\n",
      "[0.72577804 0.274222  ]\n",
      "[0.8593451 0.1406549]\n",
      "[0.71761227 0.28238773]\n",
      "[0.79577786 0.20422219]\n",
      "[0.7527492 0.2472508]\n",
      "[0.7681136  0.23188639]\n",
      "[0.7757567  0.22424333]\n",
      "[0.73628193 0.26371804]\n",
      "[0.73469514 0.26530483]\n",
      "[0.8519012  0.14809881]\n",
      "[0.7597411  0.24025884]\n",
      "[0.7795169  0.22048314]\n",
      "[0.84711707 0.15288298]\n",
      "[0.85548717 0.14451285]\n",
      "[0.8562295  0.14377052]\n",
      "[0.849451   0.15054901]\n",
      "[0.74188703 0.25811297]\n",
      "[0.7250069  0.27499315]\n",
      "[0.8620435  0.13795653]\n",
      "[0.7675321 0.2324679]\n",
      "[0.85992014 0.14007986]\n",
      "[0.8468064  0.15319362]\n",
      "[0.73710316 0.2628968 ]\n",
      "[0.7813112  0.21868882]\n",
      "[0.7505212  0.24947885]\n",
      "[0.8612759  0.13872404]\n",
      "[0.86138135 0.13861863]\n",
      "[0.70741755 0.2925825 ]\n",
      "[0.8026844  0.19731551]\n",
      "[0.7755701 0.2244299]\n",
      "[0.81251377 0.18748628]\n",
      "[0.77305466 0.2269453 ]\n",
      "[0.7382577  0.26174232]\n",
      "[0.8481109  0.15188915]\n",
      "[0.7705134  0.22948658]\n",
      "[0.859479   0.14052099]\n",
      "[0.7880304  0.21196963]\n",
      "[0.73869264 0.26130733]\n",
      "[0.85216516 0.14783481]\n",
      "[0.78036636 0.2196337 ]\n",
      "[0.8511143  0.14888565]\n",
      "[0.77648956 0.22351043]\n",
      "[0.7737424  0.22625758]\n",
      "[0.861044   0.13895604]\n",
      "[0.8547352  0.14526479]\n",
      "[0.7518043  0.24819575]\n",
      "[0.8610567  0.13894331]\n",
      "[0.8568853  0.14311475]\n",
      "[0.73334306 0.2666569 ]\n",
      "[0.73372954 0.26627043]\n",
      "[0.85752016 0.14247984]\n",
      "[0.7496141  0.25038582]\n",
      "[0.74877465 0.25122532]\n",
      "[0.8566192  0.14338084]\n",
      "[0.78094876 0.21905129]\n",
      "[0.8503417 0.1496583]\n",
      "[0.7584053  0.24159472]\n",
      "[0.76913965 0.23086034]\n",
      "[0.7585487  0.24145125]\n",
      "[0.852576   0.14742398]\n",
      "[0.80012095 0.19987907]\n",
      "[0.85891753 0.14108247]\n",
      "[0.8476676  0.15233248]\n",
      "[0.7464945  0.25350553]\n",
      "[0.8609807  0.13901936]\n",
      "[0.85609657 0.14390343]\n",
      "[0.7810098  0.21899027]\n",
      "[0.7663453  0.23365471]\n",
      "[0.7483126  0.25168747]\n",
      "[0.7771074  0.22289261]\n",
      "[0.79959995 0.20040004]\n",
      "[0.735345   0.26465493]\n",
      "[0.7532783  0.24672167]\n",
      "[0.86024106 0.13975896]\n",
      "[0.7911315  0.20886852]\n",
      "[0.8602078  0.13979219]\n",
      "[0.7957099  0.20429009]\n",
      "[9.9968290e-01 3.1717148e-04]\n",
      "[0.776219   0.22378105]\n",
      "[0.7194997  0.28050035]\n",
      "[0.76249087 0.23750916]\n",
      "[0.73726636 0.26273358]\n",
      "[0.7769759  0.22302404]\n",
      "[0.85731196 0.14268805]\n",
      "[0.86142313 0.13857687]\n",
      "[0.7497196 0.2502804]\n",
      "[0.85091656 0.14908339]\n",
      "[0.84645927 0.15354072]\n",
      "[0.8005198  0.19948019]\n",
      "[0.7932686  0.20673136]\n",
      "[0.8618645  0.13813558]\n",
      "[0.76501393 0.2349861 ]\n",
      "[0.8469637  0.15303627]\n",
      "[0.8616474  0.13835254]\n",
      "[0.7844422  0.21555784]\n",
      "[0.7587712 0.2412288]\n",
      "[0.7340878  0.26591215]\n",
      "[0.7562074 0.2437926]\n",
      "[0.8244397  0.17556034]\n",
      "[0.7886903  0.21130964]\n",
      "[0.81452    0.18547995]\n",
      "[0.84653515 0.15346487]\n",
      "[0.73568857 0.26431143]\n",
      "[0.76254237 0.2374577 ]\n",
      "[0.73001283 0.26998714]\n",
      "[0.74125874 0.25874126]\n",
      "[0.74412835 0.25587165]\n",
      "[0.787269 0.212731]\n",
      "[0.76570183 0.23429815]\n",
      "[0.7655795  0.23442052]\n",
      "[0.8500713  0.14992872]\n",
      "[0.84908473 0.15091525]\n",
      "[0.7572352  0.24276474]\n",
      "[0.78656167 0.21343836]\n",
      "[0.7526673  0.24733272]\n",
      "[0.85973245 0.14026754]\n",
      "[0.8582826  0.14171739]\n",
      "[0.7140369  0.28596312]\n",
      "[0.7625145  0.23748554]\n",
      "[0.8024824 0.1975176]\n",
      "[0.8610826  0.13891739]\n",
      "[0.79605484 0.20394517]\n",
      "[0.77681875 0.22318122]\n",
      "[0.8510696  0.14893037]\n",
      "[0.7391162 0.2608838]\n",
      "[0.75464946 0.24535052]\n",
      "[0.763915   0.23608501]\n",
      "[0.7316627  0.26833728]\n",
      "[0.85864526 0.14135471]\n",
      "[0.7527393  0.24726075]\n",
      "[0.7632388  0.23676118]\n",
      "[0.73400694 0.26599306]\n",
      "[0.79323566 0.20676433]\n",
      "[0.861372   0.13862799]\n",
      "[0.85702336 0.14297664]\n",
      "[0.7947804 0.2052196]\n",
      "[0.77878547 0.22121458]\n",
      "[0.8581548 0.1418452]\n",
      "[0.7814339 0.2185661]\n",
      "[0.85692006 0.14307998]\n",
      "[0.8546309  0.14536911]\n",
      "[0.85438156 0.1456184 ]\n",
      "[0.7497791 0.2502209]\n",
      "[0.74950224 0.2504978 ]\n",
      "[0.72632384 0.27367622]\n",
      "[0.8520323  0.14796773]\n",
      "[0.85195667 0.1480434 ]\n",
      "[0.7029627 0.2970373]\n",
      "[0.84691733 0.1530826 ]\n",
      "[0.7182347  0.28176525]\n",
      "[0.7881176  0.21188235]\n",
      "[0.85946614 0.14053385]\n",
      "[0.8572898  0.14271018]\n",
      "[0.7741161  0.22588389]\n",
      "[0.86160177 0.13839822]\n",
      "[0.85453683 0.14546318]\n",
      "[0.7756085  0.22439155]\n",
      "[0.85483617 0.14516383]\n",
      "[0.82180613 0.17819388]\n",
      "[0.7858137  0.21418639]\n",
      "[0.7800064  0.21999356]\n",
      "[0.8541371  0.14586283]\n",
      "[0.7877497  0.21225029]\n",
      "[0.7729678  0.22703217]\n",
      "[0.8160786 0.1839214]\n",
      "[0.8478574  0.15214263]\n",
      "[0.8617444  0.13825563]\n",
      "[0.8491872 0.1508128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77063084 0.22936912]\n",
      "[0.856384 0.143616]\n",
      "[0.77547365 0.22452636]\n",
      "[0.8031847  0.19681531]\n",
      "[0.7676604  0.23233962]\n",
      "[0.85331196 0.14668798]\n",
      "[0.85109305 0.14890698]\n",
      "[0.7673947  0.23260534]\n",
      "[0.7633971  0.23660292]\n",
      "[0.7336562  0.26634377]\n",
      "[0.72720444 0.27279553]\n",
      "[0.8532108  0.14678921]\n",
      "[0.742018   0.25798208]\n",
      "[0.7506774  0.24932265]\n",
      "[0.7658107  0.23418927]\n",
      "[0.85790545 0.14209451]\n",
      "[0.7601789  0.23982108]\n",
      "[0.74888134 0.25111866]\n",
      "[0.8529756  0.14702445]\n",
      "[0.85269976 0.14730027]\n",
      "[0.8477151  0.15228486]\n",
      "[0.85335857 0.14664143]\n",
      "[0.85395575 0.14604427]\n",
      "[0.75724626 0.24275379]\n",
      "[0.85316056 0.14683948]\n",
      "[0.7367257 0.2632743]\n",
      "[0.7492121 0.2507879]\n",
      "[0.79749435 0.20250563]\n",
      "[0.8491105 0.1508895]\n",
      "[0.8292698  0.17073025]\n",
      "[0.7378952  0.26210475]\n",
      "[0.7759703 0.2240297]\n",
      "[0.8122546 0.1877454]\n",
      "[0.76983577 0.23016423]\n",
      "[0.86155474 0.13844527]\n",
      "[0.84961385 0.15038614]\n",
      "[0.75745285 0.24254712]\n",
      "[0.78579503 0.21420495]\n",
      "[0.85479677 0.14520328]\n",
      "[0.76503855 0.23496144]\n",
      "[0.7366009  0.26339915]\n",
      "[0.7556891  0.24431093]\n",
      "[0.7541039 0.2458961]\n",
      "[0.77717    0.22282998]\n",
      "[0.7716901  0.22830996]\n",
      "[0.8611511  0.13884893]\n",
      "[0.7200326  0.27996743]\n",
      "[0.76765317 0.23234685]\n",
      "[0.84824127 0.15175878]\n",
      "[0.8557883  0.14421165]\n",
      "[0.8576173  0.14238268]\n",
      "[0.7747339  0.22526607]\n",
      "[0.76170427 0.23829569]\n",
      "[0.7428317  0.25716835]\n",
      "[0.8188853  0.18111464]\n",
      "[0.8585865  0.14141357]\n",
      "[0.85988444 0.14011554]\n",
      "[0.7562154  0.24378467]\n",
      "[0.80360043 0.1963996 ]\n",
      "[0.77224153 0.2277585 ]\n",
      "[0.7765206  0.22347933]\n",
      "[0.769483   0.23051699]\n",
      "[0.7759305  0.22406954]\n",
      "[0.8542187  0.14578128]\n",
      "[0.7719735 0.2280265]\n",
      "[0.7851313  0.21486871]\n",
      "[0.8082029 0.1917971]\n",
      "[0.7598432  0.24015681]\n",
      "[0.8495452  0.15045486]\n",
      "[0.85075176 0.14924823]\n",
      "[0.7582567  0.24174334]\n",
      "[0.762697   0.23730308]\n",
      "[0.85279304 0.14720699]\n",
      "[0.8467158  0.15328427]\n",
      "[0.8556005  0.14439952]\n",
      "[0.7683232  0.23167676]\n",
      "[0.85763556 0.14236447]\n",
      "[0.75142616 0.24857387]\n",
      "[0.85772896 0.14227104]\n",
      "[0.86064273 0.13935727]\n",
      "[0.7478159 0.2521841]\n",
      "[0.7524783  0.24752165]\n",
      "[0.86021405 0.13978599]\n",
      "[0.8464561  0.15354382]\n",
      "[0.7498795  0.25012055]\n",
      "[0.7981005  0.20189956]\n",
      "[0.789557 0.210443]\n",
      "[0.75280786 0.24719216]\n",
      "[0.7715869  0.22841309]\n",
      "[0.7611632  0.23883684]\n",
      "[0.7677835  0.23221648]\n",
      "[0.7436452  0.25635478]\n",
      "[0.75726575 0.24273427]\n",
      "[0.7435623 0.2564377]\n",
      "[0.8526661  0.14733396]\n",
      "[0.7212828  0.27871728]\n",
      "[0.7604328  0.23956719]\n",
      "[0.7520515  0.24794845]\n",
      "[0.7639455  0.23605448]\n",
      "[0.7415046  0.25849545]\n",
      "[0.8464714  0.15352856]\n",
      "[0.81513894 0.18486099]\n",
      "[0.7629327  0.23706725]\n",
      "[0.8606573  0.13934268]\n",
      "[0.7442859 0.2557141]\n",
      "[0.7942913  0.20570871]\n",
      "[0.7477065 0.2522935]\n",
      "[0.7825863  0.21741368]\n",
      "[0.85084075 0.14915927]\n",
      "[0.8531402  0.14685988]\n",
      "[0.7756701  0.22432983]\n",
      "[0.8588711  0.14112885]\n",
      "[0.75336885 0.24663112]\n",
      "[0.7635835  0.23641655]\n",
      "[0.7681441  0.23185597]\n",
      "[0.85641026 0.14358974]\n",
      "[0.7526733 0.2473267]\n",
      "[0.861443   0.13855703]\n",
      "[0.7729014  0.22709866]\n",
      "[0.8583065  0.14169349]\n",
      "[0.7798676  0.22013243]\n",
      "[0.78770614 0.21229386]\n",
      "[0.7836939  0.21630606]\n",
      "[0.7502947  0.24970534]\n",
      "[0.7716246 0.2283754]\n",
      "[0.7370662  0.26293385]\n",
      "[0.77316403 0.22683592]\n",
      "[0.84875405 0.151246  ]\n",
      "[0.7829377  0.21706235]\n",
      "[0.74708897 0.252911  ]\n",
      "[0.75655794 0.24344203]\n",
      "[0.8513585  0.14864151]\n",
      "[0.7768909  0.22310917]\n",
      "[0.75632936 0.24367057]\n",
      "[0.77738297 0.22261703]\n",
      "[0.84805775 0.1519423 ]\n",
      "[0.7412434  0.25875658]\n",
      "[0.7533007  0.24669924]\n",
      "[0.85882705 0.14117296]\n",
      "[0.76879793 0.23120208]\n",
      "[0.85051423 0.14948578]\n",
      "[0.73949903 0.2605009 ]\n",
      "[0.84701204 0.15298796]\n",
      "[0.79216653 0.20783342]\n",
      "[0.7505518  0.24944812]\n",
      "[0.77830863 0.2216914 ]\n",
      "[0.8551075  0.14489253]\n",
      "[0.8589948  0.14100522]\n",
      "[0.8537123  0.14628771]\n",
      "[0.73248667 0.2675133 ]\n",
      "[0.8530271  0.14697286]\n",
      "[0.73044026 0.26955977]\n",
      "[0.7882232 0.2117768]\n",
      "[0.78207254 0.21792747]\n",
      "[0.7645848  0.23541528]\n",
      "[0.85247713 0.14752284]\n",
      "[0.76775813 0.23224194]\n",
      "[0.7608356  0.23916446]\n",
      "[0.8615083 0.1384917]\n",
      "[0.8600337  0.13996628]\n",
      "[0.7475877  0.25241232]\n",
      "[0.74109554 0.25890443]\n",
      "[0.85833347 0.1416665 ]\n",
      "[0.7507793  0.24922067]\n",
      "[0.8502313  0.14976877]\n",
      "[0.7625087  0.23749135]\n",
      "[0.84830576 0.15169428]\n",
      "[0.7467355  0.25326452]\n",
      "[0.8541607  0.14583932]\n",
      "[0.8607031 0.1392969]\n",
      "[0.7279858 0.2720142]\n",
      "[0.78031105 0.21968898]\n",
      "[0.79294986 0.2070501 ]\n",
      "[0.7749426  0.22505736]\n",
      "[0.85211015 0.1478898 ]\n",
      "[0.7876966  0.21230336]\n",
      "[0.8516171 0.1483829]\n",
      "[0.79065406 0.2093459 ]\n",
      "[0.74649185 0.2535082 ]\n",
      "[0.85098493 0.14901504]\n",
      "[0.7966493  0.20335072]\n",
      "[0.74545455 0.25454548]\n",
      "[0.7529129  0.24708715]\n",
      "[0.80301315 0.19698685]\n",
      "[0.7596799  0.24032012]\n",
      "[0.74135154 0.2586484 ]\n",
      "[0.75656056 0.24343942]\n",
      "[0.7813612  0.21863882]\n",
      "[0.7603406  0.23965946]\n",
      "[0.8484733  0.15152672]\n",
      "[0.76819175 0.23180819]\n",
      "[0.86054975 0.13945022]\n",
      "[0.85883087 0.14116916]\n",
      "[0.73951626 0.2604837 ]\n",
      "[0.8572394  0.14276063]\n",
      "[0.8614104  0.13858959]\n",
      "[0.78452307 0.21547692]\n",
      "[0.8562342  0.14376575]\n",
      "[0.85313493 0.14686508]\n",
      "[0.8597794  0.14022055]\n",
      "[0.7742099  0.22579001]\n",
      "[0.7700063  0.22999369]\n",
      "[0.73758924 0.2624108 ]\n",
      "[0.7750082  0.22499177]\n",
      "[0.7675842  0.23241578]\n",
      "[0.85950077 0.14049925]\n",
      "[0.84936774 0.15063226]\n",
      "[0.8495506  0.15044935]\n",
      "[0.8488715  0.15112843]\n",
      "[0.77259654 0.22740349]\n",
      "[0.8465107  0.15348925]\n",
      "[0.85103804 0.14896199]\n",
      "[0.76475686 0.23524313]\n",
      "[0.8582099  0.14179005]\n",
      "[0.86163557 0.13836442]\n",
      "[0.8004555  0.19954447]\n",
      "[0.7472145  0.25278556]\n",
      "[0.76804686 0.23195311]\n",
      "[0.8618824 0.1381176]\n",
      "[0.8565312  0.14346884]\n",
      "[0.7621084  0.23789163]\n",
      "[0.7339864  0.26601362]\n",
      "[0.78050524 0.21949482]\n",
      "[0.7594992  0.24050076]\n",
      "[0.80634195 0.19365805]\n",
      "[0.8530785  0.14692156]\n",
      "[0.8586749 0.1413251]\n",
      "[0.7812881  0.21871191]\n",
      "[0.7958469 0.2041531]\n",
      "[0.7816886  0.21831138]\n",
      "[0.85744846 0.1425515 ]\n",
      "[0.85093176 0.14906819]\n",
      "[0.7651964 0.2348036]\n",
      "[0.8479191  0.15208085]\n",
      "[0.7714358  0.22856426]\n",
      "[0.7619431  0.23805694]\n",
      "[0.7719793 0.2280207]\n",
      "[0.79887944 0.20112059]\n",
      "[0.79464334 0.2053566 ]\n",
      "[0.74012893 0.25987104]\n",
      "[0.7710419  0.22895804]\n",
      "[0.85967714 0.14032292]\n",
      "[0.8482449  0.15175511]\n",
      "[0.79793954 0.20206048]\n",
      "[0.8472576  0.15274234]\n",
      "[0.8046132  0.19538684]\n",
      "[0.76402974 0.23597024]\n",
      "[0.78727096 0.21272905]\n",
      "[0.7363532  0.26364678]\n",
      "[0.7739279  0.22607204]\n",
      "[0.7590604  0.24093959]\n",
      "[0.84713936 0.15286066]\n",
      "[0.75595385 0.24404618]\n",
      "[0.72398347 0.27601653]\n",
      "[0.85138327 0.14861672]\n",
      "[0.7649607  0.23503935]\n",
      "[0.859861   0.14013901]\n",
      "[0.7964704  0.20352961]\n",
      "[0.86001337 0.1399866 ]\n",
      "[0.861883   0.13811702]\n",
      "[0.8477766  0.15222335]\n",
      "[0.7658338  0.23416618]\n",
      "[0.7346504  0.26534966]\n",
      "[0.8488164  0.15118359]\n",
      "[0.8546844 0.1453156]\n",
      "[0.7329231 0.2670769]\n",
      "[0.76352805 0.23647188]\n",
      "[0.85621804 0.14378199]\n",
      "[0.85184115 0.14815879]\n",
      "[0.7476153  0.25238472]\n",
      "[0.78198874 0.21801129]\n",
      "[0.75813854 0.24186148]\n",
      "[0.8604543  0.13954565]\n",
      "[0.861072   0.13892804]\n",
      "[0.76236147 0.23763846]\n",
      "[0.8543648  0.14563522]\n",
      "[0.8508803  0.14911968]\n",
      "[0.7355628 0.2644373]\n",
      "[0.77181643 0.2281836 ]\n",
      "[0.86062735 0.13937266]\n",
      "[0.8587515  0.14124852]\n",
      "[0.7628401  0.23715988]\n",
      "[0.8580405  0.14195947]\n",
      "[0.8510023  0.14899768]\n",
      "[0.73545146 0.26454854]\n",
      "[0.8616759  0.13832407]\n",
      "[0.783917 0.216083]\n",
      "[0.7850637  0.21493636]\n",
      "[0.860549   0.13945107]\n",
      "[0.77788675 0.22211325]\n",
      "[0.85186166 0.14813837]\n",
      "[0.7787904  0.22120956]\n",
      "[0.8469173  0.15308274]\n",
      "[0.8569218 0.1430782]\n",
      "[0.7464871  0.25351295]\n",
      "[0.7547592  0.24524076]\n",
      "[0.8181112 0.1818888]\n",
      "[0.85915506 0.14084497]\n",
      "[0.7510786 0.2489213]\n",
      "[0.8499217 0.1500783]\n",
      "[0.76455855 0.23544149]\n",
      "[0.7413419  0.25865814]\n",
      "[0.7542526  0.24574743]\n",
      "[0.72009903 0.27990097]\n",
      "[0.84936714 0.15063289]\n",
      "[0.77183527 0.22816479]\n",
      "[0.7261544  0.27384558]\n",
      "[0.85991126 0.14008875]\n",
      "[0.7362406  0.26375932]\n",
      "[0.74113595 0.25886405]\n",
      "[0.85533637 0.14466365]\n",
      "[0.79088897 0.20911105]\n",
      "[0.7874515  0.21254852]\n",
      "[0.7766691  0.22333091]\n",
      "[0.745926 0.254074]\n",
      "[0.78259635 0.2174037 ]\n",
      "[0.85497683 0.14502311]\n",
      "[0.8129392  0.18706068]\n",
      "[0.847841   0.15215895]\n",
      "[0.76876456 0.2312355 ]\n",
      "[0.79302764 0.20697235]\n",
      "[0.7724233  0.22757664]\n",
      "[0.85461974 0.14538023]\n",
      "[0.857576   0.14242394]\n",
      "[0.7667376  0.23326243]\n",
      "[0.7643175  0.23568247]\n",
      "[0.7392083 0.2607917]\n",
      "[0.737659   0.26234093]\n",
      "[0.8515089  0.14849105]\n",
      "[0.75820845 0.24179156]\n",
      "[0.85720414 0.14279595]\n",
      "[0.76215804 0.23784192]\n",
      "[0.7797252  0.22027478]\n",
      "[0.7885129  0.21148705]\n",
      "[0.77689713 0.22310288]\n",
      "[0.7230227  0.27697727]\n",
      "[0.84781164 0.15218832]\n",
      "[0.7609056  0.23909438]\n",
      "[0.77059793 0.22940208]\n",
      "[0.76531214 0.23468788]\n",
      "[0.8584323  0.14156774]\n",
      "[0.7444076  0.25559238]\n",
      "[0.7624874  0.23751259]\n",
      "[0.7449347  0.25506532]\n",
      "[0.8465809 0.1534191]\n",
      "[0.7439672  0.25603276]\n",
      "[0.7913724  0.20862755]\n",
      "[0.759955 0.240045]\n",
      "[0.7602707  0.23972926]\n",
      "[0.7895987  0.21040127]\n",
      "[0.8550677 0.1449323]\n",
      "[0.7773458  0.22265421]\n",
      "[0.8578354  0.14216456]\n",
      "[0.8471727  0.15282732]\n",
      "[0.79587144 0.20412862]\n",
      "[0.7638211  0.23617892]\n",
      "[0.85417825 0.1458217 ]\n",
      "[0.85648435 0.14351572]\n",
      "[0.73379254 0.26620746]\n",
      "[0.73542196 0.26457807]\n",
      "[0.7585635  0.24143647]\n",
      "[0.7753314  0.22466856]\n",
      "[0.7515382 0.2484618]\n",
      "[0.8622404  0.13775963]\n",
      "[0.752686 0.247314]\n",
      "[0.7608772  0.23912282]\n",
      "[0.8610294 0.1389706]\n",
      "[0.84713995 0.15286003]\n",
      "[0.85824084 0.14175916]\n",
      "[0.7693067 0.2306933]\n",
      "[0.84673375 0.15326627]\n",
      "[0.7805316  0.21946843]\n",
      "[0.77717525 0.2228248 ]\n",
      "[0.7700655  0.22993457]\n",
      "[0.7751533  0.22484672]\n",
      "[0.8560078 0.1439922]\n",
      "[0.85237575 0.14762422]\n",
      "[0.8574857  0.14251432]\n",
      "[0.8543809  0.14561914]\n",
      "[0.8506004 0.1493995]\n",
      "[0.7797913  0.22020875]\n",
      "[0.85871184 0.14128815]\n",
      "[0.74009454 0.2599055 ]\n",
      "[0.80509305 0.19490701]\n",
      "[0.85801846 0.14198151]\n",
      "[0.7978252  0.20217481]\n",
      "[0.7205879 0.2794121]\n",
      "[0.7010042 0.2989958]\n",
      "[0.8571759  0.14282408]\n",
      "[0.80342877 0.1965712 ]\n",
      "[0.7614232  0.23857687]\n",
      "[0.76491106 0.23508902]\n",
      "[0.859794   0.14020598]\n",
      "[0.7569397  0.24306026]\n",
      "[0.75093454 0.24906543]\n",
      "[0.84726405 0.15273592]\n",
      "[0.7776732  0.22232689]\n",
      "[0.7375075  0.26249254]\n",
      "[0.7347026  0.26529738]\n",
      "[0.7373362  0.26266372]\n",
      "[0.85422385 0.1457762 ]\n",
      "[0.78033346 0.21966657]\n",
      "[0.73770547 0.2622946 ]\n",
      "[0.75046754 0.24953248]\n",
      "[0.7808469  0.21915305]\n",
      "[0.84985733 0.15014262]\n",
      "[0.7687964  0.23120357]\n",
      "[0.77842444 0.22157553]\n",
      "[0.85368264 0.1463174 ]\n",
      "[0.8470011 0.1529989]\n",
      "[0.7578077  0.24219239]\n",
      "[0.77977204 0.22022794]\n",
      "[0.86037844 0.1396216 ]\n",
      "[0.8587723  0.14122768]\n",
      "[0.79432046 0.2056795 ]\n",
      "[0.8546961 0.1453039]\n",
      "[0.74969023 0.25030974]\n",
      "[0.849859   0.15014102]\n",
      "[0.71285653 0.28714347]\n",
      "[0.7554156  0.24458435]\n",
      "[0.8490266  0.15097333]\n",
      "[0.8577716  0.14222844]\n",
      "[0.74838096 0.25161904]\n",
      "[0.78498083 0.21501921]\n",
      "[0.75324553 0.24675442]\n",
      "[0.85773826 0.14226173]\n",
      "[0.7453563  0.25464374]\n",
      "[0.7319008  0.26809913]\n",
      "[0.759401   0.24059902]\n",
      "[0.7762282  0.22377177]\n",
      "[0.76307243 0.2369276 ]\n",
      "[0.7784384  0.22156154]\n",
      "[0.7437265 0.2562735]\n",
      "[0.7678384  0.23216158]\n",
      "[0.7611014  0.23889855]\n",
      "[0.8577839  0.14221606]\n",
      "[0.7679972  0.23200274]\n",
      "[0.78579146 0.21420853]\n",
      "[0.7530668  0.24693327]\n",
      "[0.75286084 0.2471392 ]\n",
      "[0.752771 0.247229]\n",
      "[0.7409017 0.2590982]\n",
      "[0.73865974 0.2613402 ]\n",
      "[0.8612128  0.13878715]\n",
      "[0.85103 0.14897]\n",
      "[0.8623002  0.13769978]\n",
      "[0.7598774  0.24012262]\n",
      "[0.77048177 0.22951818]\n",
      "[0.7513734 0.2486266]\n",
      "[0.761424   0.23857607]\n",
      "[0.85565424 0.14434585]\n",
      "[0.75719273 0.24280733]\n",
      "[0.7772762  0.22272383]\n",
      "[0.7519738 0.2480262]\n",
      "[0.84690523 0.15309481]\n",
      "[0.7513056  0.24869438]\n",
      "[0.8540312 0.1459688]\n",
      "[0.7851386  0.21486132]\n",
      "[0.8542128  0.14578724]\n",
      "[0.76111335 0.2388866 ]\n",
      "[0.76093835 0.23906167]\n",
      "[0.7579503  0.24204972]\n",
      "[0.78488004 0.2151199 ]\n",
      "[0.85714823 0.1428518 ]\n",
      "[0.7712328  0.22876717]\n",
      "[0.8030468  0.19695313]\n",
      "[0.8467186 0.1532814]\n",
      "[0.7319252  0.26807478]\n",
      "[0.8552252  0.14477485]\n",
      "[0.7762598 0.2237402]\n",
      "[0.8468525  0.15314758]\n",
      "[0.75165445 0.24834557]\n",
      "[0.7632909  0.23670907]\n",
      "[0.7764102 0.2235898]\n",
      "[0.85694957 0.14305049]\n",
      "[0.8517455  0.14825448]\n",
      "[0.7622021  0.23779787]\n",
      "[0.7467808  0.25321928]\n",
      "[0.85698247 0.14301752]\n",
      "[0.85473275 0.14526723]\n",
      "[0.7354556  0.26454443]\n",
      "[0.8571656 0.1428344]\n",
      "[0.7942922  0.20570783]\n",
      "[0.8592289  0.14077114]\n",
      "[0.8554675  0.14453256]\n",
      "[0.7755581 0.2244419]\n",
      "[0.76596326 0.23403677]\n",
      "[0.75909716 0.24090281]\n",
      "[0.85750246 0.1424975 ]\n",
      "[0.77024245 0.22975753]\n",
      "[0.74551487 0.25448507]\n",
      "[0.78745097 0.21254906]\n",
      "[0.8613258  0.13867414]\n",
      "[0.8610356  0.13896443]\n",
      "[0.85060483 0.14939514]\n",
      "[0.85185194 0.14814804]\n",
      "[0.86192113 0.13807885]\n",
      "[0.8619311  0.13806896]\n",
      "[0.85736156 0.14263844]\n",
      "[0.8484221 0.1515779]\n",
      "[0.86007965 0.13992034]\n",
      "[0.7708756  0.22912437]\n",
      "[0.7377781  0.26222187]\n",
      "[0.74090827 0.2590917 ]\n",
      "[0.76813513 0.23186484]\n",
      "[0.77093875 0.22906126]\n",
      "[0.7953198  0.20468019]\n",
      "[0.85624087 0.14375916]\n",
      "[0.79913783 0.20086217]\n",
      "[0.86140496 0.13859497]\n",
      "[0.8581354  0.14186463]\n",
      "[0.74661976 0.25338027]\n",
      "[0.859937   0.14006302]\n",
      "[0.85353035 0.14646967]\n",
      "[0.7788533  0.22114673]\n",
      "[0.78255534 0.21744469]\n",
      "[0.7693413  0.23065868]\n",
      "[0.73023546 0.26976457]\n",
      "[0.75345165 0.24654841]\n",
      "[0.77633643 0.22366352]\n",
      "[0.77708834 0.22291169]\n",
      "[0.85429925 0.14570077]\n",
      "[0.7732259 0.2267741]\n",
      "[0.7751374  0.22486258]\n",
      "[0.8011517  0.19884829]\n",
      "[0.75345886 0.24654113]\n",
      "[0.7628063  0.23719373]\n",
      "[0.72365654 0.27634344]\n",
      "[0.84671015 0.1532899 ]\n",
      "[0.8597897  0.14021029]\n",
      "[0.86022246 0.13977757]\n",
      "[0.7373367 0.2626633]\n",
      "[0.7987752  0.20122474]\n",
      "[0.8573459  0.14265418]\n",
      "[0.77741617 0.22258389]\n",
      "[0.8546555  0.14534451]\n",
      "[0.85073096 0.14926901]\n",
      "[0.7860025 0.2139975]\n",
      "[0.79536325 0.20463674]\n",
      "[0.8590612  0.14093876]\n",
      "[0.7815434  0.21845666]\n",
      "[0.8487911  0.15120889]\n",
      "[0.7410292  0.25897074]\n",
      "[0.8622804  0.13771957]\n",
      "[0.8565315  0.14346857]\n",
      "[0.7824     0.21760005]\n",
      "[0.7986464  0.20135365]\n",
      "[0.857235 0.142765]\n",
      "[0.75802946 0.24197054]\n",
      "[0.7679031  0.23209688]\n",
      "[0.79192805 0.20807196]\n",
      "[0.859387 0.140613]\n",
      "[0.77787983 0.2221202 ]\n",
      "[0.79332966 0.2066704 ]\n",
      "[0.86162907 0.13837092]\n",
      "[0.7978121  0.20218788]\n",
      "[0.8494235  0.15057641]\n",
      "[0.86032736 0.13967265]\n",
      "[0.7350049  0.26499513]\n",
      "[0.85481226 0.14518772]\n",
      "[0.8580249  0.14197513]\n",
      "[0.8611505  0.13884956]\n",
      "[0.803256   0.19674401]\n",
      "[0.7517419 0.2482581]\n",
      "[0.7802909  0.21970905]\n",
      "[0.8041864  0.19581366]\n",
      "[0.7704447  0.22955535]\n",
      "[0.737996 0.262004]\n",
      "[0.78253824 0.21746181]\n",
      "[0.8506902  0.14930984]\n",
      "[0.7439387  0.25606132]\n",
      "[0.77148205 0.228518  ]\n",
      "[0.75057405 0.24942596]\n",
      "[0.84672135 0.15327866]\n",
      "[0.77383435 0.22616564]\n",
      "[0.8546961  0.14530393]\n",
      "[0.80502063 0.19497935]\n",
      "[0.8464645  0.15353547]\n",
      "[0.85659087 0.14340915]\n",
      "[0.7640108 0.2359892]\n",
      "[0.7800197  0.21998025]\n",
      "[0.74910235 0.25089765]\n",
      "[0.7874074  0.21259254]\n",
      "[0.72008663 0.2799134 ]\n",
      "[0.8551584  0.14484161]\n",
      "[0.76907605 0.23092395]\n",
      "[0.77030224 0.2296978 ]\n",
      "[0.76304066 0.23695937]\n",
      "[0.7602144 0.2397856]\n",
      "[0.7586213  0.24137877]\n",
      "[0.7461317  0.25386834]\n",
      "[0.77115494 0.22884504]\n",
      "[0.8596418 0.1403582]\n",
      "[0.77170134 0.22829865]\n",
      "[0.8542503  0.14574969]\n",
      "[0.76043534 0.23956463]\n",
      "[0.78403366 0.21596639]\n",
      "[0.8526237  0.14737628]\n",
      "[0.74737716 0.25262287]\n",
      "[0.85189027 0.1481097 ]\n",
      "[0.72332853 0.2766715 ]\n",
      "[0.85428727 0.14571272]\n",
      "[0.7798152  0.22018473]\n",
      "[0.85226244 0.14773756]\n",
      "[0.8493831  0.15061682]\n",
      "[0.86208147 0.13791847]\n",
      "[0.7342602  0.26573977]\n",
      "[0.7488065  0.25119352]\n",
      "[0.7822591  0.21774086]\n",
      "[0.75173193 0.24826805]\n",
      "[0.7781678 0.2218322]\n",
      "[0.7856224  0.21437761]\n",
      "[0.8608332  0.13916676]\n",
      "[0.8532073  0.14679274]\n",
      "[0.7316847  0.26831535]\n",
      "[0.7739941 0.2260059]\n",
      "[0.78011066 0.21988937]\n",
      "[0.81093454 0.18906547]\n",
      "[0.7509583  0.24904166]\n",
      "[0.76542693 0.23457308]\n",
      "[0.7442522 0.2557478]\n",
      "[0.79781014 0.20218983]\n",
      "[0.79716235 0.20283768]\n",
      "[0.7716065  0.22839352]\n",
      "[0.77118176 0.22881822]\n",
      "[1.000000e+00 8.474827e-15]\n",
      "[0.8559353  0.14406475]\n",
      "[0.7669804  0.23301959]\n",
      "[0.76538086 0.23461913]\n",
      "[0.7158798 0.2841202]\n",
      "[0.78108615 0.2189139 ]\n",
      "[0.76093596 0.23906402]\n",
      "[0.74942946 0.25057057]\n",
      "[0.74905145 0.2509485 ]\n",
      "[0.8464442  0.15355584]\n",
      "[0.76810575 0.23189425]\n",
      "[0.8600567  0.13994332]\n",
      "[0.79112303 0.20887704]\n",
      "[0.7641703  0.23582973]\n",
      "[0.7840383  0.21596162]\n",
      "[0.74063927 0.25936067]\n",
      "[0.8547437  0.14525625]\n",
      "[0.7522154 0.2477846]\n",
      "[0.7808908  0.21910915]\n",
      "[0.7806315  0.21936849]\n",
      "[0.8019481 0.1980519]\n",
      "[0.7511921  0.24880792]\n",
      "[0.85424656 0.14575347]\n",
      "[0.8580829  0.14191706]\n",
      "[0.77777046 0.2222296 ]\n",
      "[0.8559693  0.14403069]\n",
      "[0.7722098  0.22779019]\n",
      "[0.85872525 0.14127477]\n",
      "[0.7688796  0.23112036]\n",
      "[0.73821235 0.26178765]\n",
      "[0.7719778  0.22802222]\n",
      "[0.79243207 0.20756793]\n",
      "[0.7759446  0.22405545]\n",
      "[0.76071084 0.23928915]\n",
      "[0.85241175 0.1475882 ]\n",
      "[0.7594351 0.2405649]\n",
      "[0.86133474 0.1386652 ]\n",
      "[0.77447    0.22553004]\n",
      "[0.8577398 0.1422602]\n",
      "[0.78371847 0.21628153]\n",
      "[0.76585007 0.23414987]\n",
      "[0.75793475 0.24206527]\n",
      "[0.7655861  0.23441385]\n",
      "[0.85139114 0.14860882]\n",
      "[0.76901996 0.23098001]\n",
      "[0.787708   0.21229199]\n",
      "[0.7425303  0.25746977]\n",
      "[0.8504741 0.1495259]\n",
      "[0.75942075 0.24057922]\n",
      "[0.7386453 0.2613547]\n",
      "[0.85365194 0.14634801]\n",
      "[0.7508323  0.24916771]\n",
      "[0.76607853 0.23392148]\n",
      "[0.79760873 0.20239127]\n",
      "[0.7569826  0.24301738]\n",
      "[0.7731782  0.22682177]\n",
      "[0.78642905 0.213571  ]\n",
      "[0.85981554 0.14018452]\n",
      "[0.77002645 0.22997354]\n",
      "[0.72767323 0.27232686]\n",
      "[0.8549419  0.14505805]\n",
      "[0.77161425 0.22838578]\n",
      "[0.76912075 0.23087926]\n",
      "[0.7401125 0.2598875]\n",
      "[0.8506541  0.14934596]\n",
      "[0.7664818  0.23351815]\n",
      "[0.7620355 0.2379645]\n",
      "[0.77996737 0.22003269]\n",
      "[0.73266894 0.26733103]\n",
      "[0.8595421  0.14045796]\n",
      "[0.8606446  0.13935548]\n",
      "[0.859914   0.14008602]\n",
      "[0.79597753 0.2040225 ]\n",
      "[0.7845722  0.21542788]\n",
      "[0.8575387  0.14246133]\n",
      "[0.780931   0.21906899]\n",
      "[0.76507074 0.23492926]\n",
      "[0.7590931  0.24090691]\n",
      "[0.7582957  0.24170423]\n",
      "[0.85302526 0.1469747 ]\n",
      "[0.7878222  0.21217778]\n",
      "[0.8064213  0.19357872]\n",
      "[0.74750906 0.25249097]\n",
      "[0.80207115 0.19792886]\n",
      "[0.75230473 0.24769527]\n",
      "[0.79432654 0.20567343]\n",
      "[0.748266 0.251734]\n",
      "[0.85095567 0.14904429]\n",
      "[0.8598734  0.14012651]\n",
      "[0.8606074  0.13939261]\n",
      "[0.85466796 0.14533202]\n",
      "[0.7578155  0.24218452]\n",
      "[0.8493173  0.15068266]\n",
      "[0.7806936  0.21930641]\n",
      "[0.750972   0.24902804]\n",
      "[0.7626734 0.2373266]\n",
      "[0.8568973  0.14310272]\n",
      "[0.8558458  0.14415418]\n",
      "[0.8476945  0.15230542]\n",
      "[0.8618581  0.13814184]\n",
      "[0.849673   0.15032706]\n",
      "[0.80269104 0.19730888]\n",
      "[0.86111724 0.13888271]\n",
      "[0.7550585  0.24494153]\n",
      "[0.8611655  0.13883448]\n",
      "[0.76940966 0.23059033]\n",
      "[0.76093733 0.23906273]\n",
      "[0.7392201  0.26077992]\n",
      "[0.8526883  0.14731163]\n",
      "[0.85814565 0.14185433]\n",
      "[0.8618213  0.13817868]\n",
      "[0.84945804 0.15054199]\n",
      "[0.761383   0.23861702]\n",
      "[0.76218706 0.23781295]\n",
      "[0.84667945 0.1533205 ]\n",
      "[0.85857725 0.14142278]\n",
      "[0.7789858  0.22101426]\n",
      "[0.80720246 0.19279754]\n",
      "[0.85569507 0.1443049 ]\n",
      "[0.80246985 0.19753014]\n",
      "[0.7494105  0.25058952]\n",
      "[0.8020985  0.19790147]\n",
      "[0.77280974 0.22719027]\n",
      "[0.7574739  0.24252619]\n",
      "[0.7783056  0.22169438]\n",
      "[0.75066316 0.24933682]\n",
      "[0.8575497  0.14245023]\n",
      "[0.84837276 0.15162721]\n",
      "[0.85084414 0.14915581]\n",
      "[0.7359581 0.2640419]\n",
      "[0.75648    0.24351999]\n",
      "[0.85585237 0.14414765]\n",
      "[0.74496776 0.25503227]\n",
      "[0.84914935 0.15085065]\n",
      "[0.76546913 0.2345309 ]\n",
      "[0.7620415  0.23795842]\n",
      "[0.77118003 0.22881994]\n",
      "[0.7471551  0.25284493]\n",
      "[0.7808848 0.2191152]\n",
      "[0.85704255 0.14295743]\n",
      "[0.8538376  0.14616232]\n",
      "[0.7562995  0.24370047]\n",
      "[0.7859503  0.21404968]\n",
      "[0.7820469  0.21795309]\n",
      "[0.778981   0.22101897]\n",
      "[0.8469409  0.15305912]\n",
      "[0.86074567 0.13925432]\n",
      "[0.7693318  0.23066813]\n",
      "[0.79071033 0.20928971]\n",
      "[0.8465117 0.1534882]\n",
      "[0.78384984 0.21615015]\n",
      "[0.7657091  0.23429091]\n",
      "[0.8472497  0.15275031]\n",
      "[0.77692    0.22307998]\n",
      "[0.78822416 0.21177582]\n",
      "[0.76471627 0.23528369]\n",
      "[0.75338054 0.24661948]\n",
      "[0.7763317  0.22366832]\n",
      "[0.86086035 0.13913968]\n",
      "[0.7475609 0.2524391]\n",
      "[0.7477039  0.25229615]\n",
      "[0.78197765 0.21802239]\n",
      "[0.75126386 0.24873613]\n",
      "[0.770862   0.22913799]\n",
      "[0.74774325 0.2522567 ]\n",
      "[0.77913105 0.2208689 ]\n",
      "[0.84864527 0.15135472]\n",
      "[0.7325557  0.26744425]\n",
      "[0.8540594  0.14594066]\n",
      "[0.74871653 0.25128344]\n",
      "[0.85051835 0.14948168]\n",
      "[0.78169036 0.21830958]\n",
      "[0.74040675 0.25959322]\n",
      "[0.84830964 0.15169044]\n",
      "[0.85522   0.1447799]\n",
      "[0.740954   0.25904605]\n",
      "[0.7686868  0.23131327]\n",
      "[0.76372534 0.23627464]\n",
      "[0.71775985 0.28224015]\n",
      "[0.8531989  0.14680107]\n",
      "[0.7344849  0.26551512]\n",
      "[0.7546373  0.24536265]\n",
      "[0.86063087 0.13936907]\n",
      "[0.7499857  0.25001433]\n",
      "[0.755081   0.24491899]\n",
      "[0.8510184 0.1489815]\n",
      "[0.769778   0.23022203]\n",
      "[0.8561434  0.14385661]\n",
      "[0.7828333  0.21716669]\n",
      "[0.73934364 0.2606564 ]\n",
      "[0.8508524  0.14914764]\n",
      "[0.7322537 0.2677463]\n",
      "[0.765977 0.234023]\n",
      "[0.79012686 0.20987311]\n",
      "[0.85616595 0.14383408]\n",
      "[0.7269057 0.2730943]\n",
      "[0.8470241  0.15297595]\n",
      "[0.75627935 0.24372073]\n",
      "[0.8519151  0.14808486]\n",
      "[0.8551245  0.14487554]\n",
      "[0.8556411  0.14435886]\n",
      "[0.7516673  0.24833268]\n",
      "[0.8475012  0.15249872]\n",
      "[0.7512039  0.24879618]\n",
      "[0.7952179  0.20478208]\n",
      "[0.7869027  0.21309724]\n",
      "[0.76220036 0.23779963]\n",
      "[0.85924035 0.14075968]\n",
      "[0.73025817 0.2697418 ]\n",
      "[0.85813874 0.14186126]\n",
      "[0.86009824 0.13990174]\n",
      "[0.8489959 0.151004 ]\n",
      "[0.78610486 0.21389517]\n",
      "[0.75042814 0.24957182]\n",
      "[0.84828997 0.15171008]\n",
      "[0.75841326 0.24158673]\n",
      "[0.8606804  0.13931952]\n",
      "[0.7726304  0.22736964]\n",
      "[0.8555228 0.1444772]\n",
      "[0.7721133  0.22788675]\n",
      "[0.78112906 0.21887095]\n",
      "[0.7644721  0.23552784]\n",
      "[0.79839563 0.2016044 ]\n",
      "[0.75720733 0.24279267]\n",
      "[0.8083931  0.19160694]\n",
      "[0.71250963 0.2874904 ]\n",
      "[0.7404574  0.25954255]\n",
      "[0.74943066 0.25056937]\n",
      "[0.86203444 0.13796556]\n",
      "[0.7839074 0.2160926]\n",
      "[0.7622795  0.23772049]\n",
      "[0.74374187 0.2562582 ]\n",
      "[0.8555183 0.1444817]\n",
      "[0.76559204 0.23440796]\n",
      "[0.8531082  0.14689173]\n",
      "[0.85088587 0.14911418]\n",
      "[0.8541706  0.14582933]\n",
      "[0.8532287 0.1467714]\n",
      "[0.7636546  0.23634548]\n",
      "[0.85883385 0.1411661 ]\n",
      "[0.7673912 0.2326088]\n",
      "[0.8620076  0.13799246]\n",
      "[0.84785444 0.15214561]\n",
      "[0.8543332  0.14566682]\n",
      "[0.8535874  0.14641263]\n",
      "[0.85531014 0.14468986]\n",
      "[0.8553516  0.14464834]\n",
      "[0.8604457  0.13955434]\n",
      "[0.7717876  0.22821237]\n",
      "[0.8490719 0.1509281]\n",
      "[0.853244   0.14675601]\n",
      "[0.747102   0.25289795]\n",
      "[0.7441313  0.25586867]\n",
      "[0.8606512  0.13934878]\n",
      "[0.7846842  0.21531583]\n",
      "[0.7542211 0.245779 ]\n",
      "[0.80716515 0.19283487]\n",
      "[0.7979179  0.20208208]\n",
      "[0.7643016  0.23569845]\n",
      "[0.8608133  0.13918668]\n",
      "[0.8570602 0.1429398]\n",
      "[0.85366833 0.14633164]\n",
      "[0.85608095 0.14391907]\n",
      "[0.7246192  0.27538082]\n",
      "[0.8605028  0.13949722]\n",
      "[0.7715812  0.22841884]\n",
      "[0.7452999  0.25470015]\n",
      "[0.7636313 0.2363687]\n",
      "[0.7840533  0.21594666]\n",
      "[0.85275185 0.1472481 ]\n",
      "[0.78743017 0.21256977]\n",
      "[0.7665084  0.23349166]\n",
      "[0.78181154 0.2181884 ]\n",
      "[0.8565677  0.14343229]\n",
      "[0.80610645 0.1938936 ]\n",
      "[0.76825285 0.23174717]\n",
      "[0.85038286 0.14961712]\n",
      "[0.8469786  0.15302145]\n",
      "[0.77591085 0.2240892 ]\n",
      "[0.7457133  0.25428674]\n",
      "[0.7020869 0.2979131]\n",
      "[0.804095   0.19590504]\n",
      "[0.8592642  0.14073582]\n",
      "[0.76892716 0.23107277]\n",
      "[0.85074496 0.14925507]\n",
      "[0.7694313  0.23056863]\n",
      "[0.7761891  0.22381088]\n",
      "[0.7646474  0.23535262]\n",
      "[0.86042714 0.13957283]\n",
      "[0.7808421 0.2191579]\n",
      "[0.85470873 0.14529125]\n",
      "[0.85809094 0.14190908]\n",
      "[0.85086215 0.14913785]\n",
      "[0.76085323 0.23914678]\n",
      "[0.77465504 0.22534491]\n",
      "[0.7851285  0.21487148]\n",
      "[0.85371804 0.14628196]\n",
      "[0.84702927 0.15297073]\n",
      "[0.8571872  0.14281279]\n",
      "[0.77715737 0.22284262]\n",
      "[0.78942794 0.21057212]\n",
      "[0.7862213  0.21377866]\n",
      "[0.8315703  0.16842966]\n",
      "[0.7460324  0.25396755]\n",
      "[0.7769253  0.22307466]\n",
      "[0.7547779  0.24522206]\n",
      "[0.85337466 0.14662538]\n",
      "[0.8606538  0.13934614]\n",
      "[0.7455933 0.2544067]\n",
      "[0.7788072  0.22119279]\n",
      "[0.7375608  0.26243916]\n",
      "[0.7577953  0.24220471]\n",
      "[0.7938481  0.20615187]\n",
      "[0.76216877 0.23783125]\n",
      "[0.85277665 0.14722335]\n",
      "[0.7487862  0.25121376]\n",
      "[0.85163885 0.14836115]\n",
      "[0.77795386 0.22204617]\n",
      "[0.77400583 0.22599413]\n",
      "[0.86203134 0.13796869]\n",
      "[0.741016  0.2589841]\n",
      "[0.7587171 0.2412829]\n",
      "[0.7427402  0.25725985]\n",
      "[0.84914863 0.15085135]\n",
      "[0.8498185  0.15018141]\n",
      "[0.7672822  0.23271778]\n",
      "[0.79431874 0.2056812 ]\n",
      "[0.77355915 0.22644079]\n",
      "[0.86055267 0.1394473 ]\n",
      "[0.7711865  0.22881348]\n",
      "[0.7662767  0.23372331]\n",
      "[0.73459053 0.26540953]\n",
      "[0.795703   0.20429702]\n",
      "[0.858214   0.14178592]\n",
      "[0.7538431  0.24615683]\n",
      "[0.7791638  0.22083624]\n",
      "[0.7693541  0.23064588]\n",
      "[0.85325533 0.14674473]\n",
      "[0.8503778  0.14962225]\n",
      "[0.8588555  0.14114459]\n",
      "[0.7459857  0.25401437]\n",
      "[0.7680284  0.23197159]\n",
      "[0.85179365 0.14820635]\n",
      "[0.7973699 0.2026301]\n",
      "[0.74488115 0.25511882]\n",
      "[0.79423213 0.20576786]\n",
      "[0.7806443  0.21935566]\n",
      "[0.73330384 0.26669618]\n",
      "[0.8600975  0.13990244]\n",
      "[0.784773   0.21522701]\n",
      "[0.7431614  0.25683856]\n",
      "[0.70741117 0.29258886]\n",
      "[0.7773239  0.22267616]\n",
      "[0.740241   0.25975895]\n",
      "[0.77256274 0.2274373 ]\n",
      "[0.7688621  0.23113784]\n",
      "[0.767847   0.23215301]\n",
      "[0.75024194 0.24975811]\n",
      "[0.7684887  0.23151135]\n",
      "[0.73839843 0.2616016 ]\n",
      "[0.7579844 0.2420156]\n",
      "[0.8479775 0.1520225]\n",
      "[0.7531332  0.24686685]\n",
      "[0.8540864  0.14591354]\n",
      "[0.7568726  0.24312747]\n",
      "[0.85697985 0.14302015]\n",
      "[0.76992255 0.23007743]\n",
      "[0.8553106 0.1446894]\n",
      "[0.8594821 0.1405179]\n",
      "[0.7669304  0.23306955]\n",
      "[0.7713618  0.22863814]\n",
      "[0.7899275  0.21007247]\n",
      "[0.7886903  0.21130966]\n",
      "[0.77077407 0.22922589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8015854  0.19841462]\n",
      "[0.79655015 0.20344983]\n",
      "[0.8591838 0.1408162]\n",
      "[0.7620993  0.23790064]\n",
      "[0.8474533  0.15254672]\n",
      "[0.75861704 0.24138294]\n",
      "[0.7821571  0.21784283]\n",
      "[0.8619588 0.1380412]\n",
      "[0.85606617 0.14393379]\n",
      "[0.7522433  0.24775675]\n",
      "[0.8609642  0.13903584]\n",
      "[0.76176804 0.23823191]\n",
      "[0.7931632 0.2068368]\n",
      "[0.74024296 0.25975698]\n",
      "[0.85184944 0.14815053]\n",
      "[0.7799077  0.22009228]\n",
      "[0.76070493 0.23929507]\n",
      "[0.859196   0.14080402]\n",
      "[0.80485755 0.19514242]\n",
      "[0.8467245  0.15327549]\n",
      "[0.7497326  0.25026748]\n",
      "[0.78245014 0.21754986]\n",
      "[0.8598853  0.14011471]\n",
      "[0.85505354 0.14494646]\n",
      "[0.8501909  0.14980915]\n",
      "[0.85414183 0.14585821]\n",
      "[0.7130433  0.28695676]\n",
      "[0.8549687  0.14503118]\n",
      "[0.7903687  0.20963128]\n",
      "[0.8485443  0.15145566]\n",
      "[0.85818636 0.14181358]\n",
      "[0.76021063 0.23978934]\n",
      "[0.7721117  0.22788826]\n",
      "[0.73636615 0.26363382]\n",
      "[0.8494807  0.15051931]\n",
      "[0.7620007  0.23799933]\n",
      "[0.7907919  0.20920804]\n",
      "[0.8520856  0.14791444]\n",
      "[0.7729121  0.22708793]\n",
      "[0.85729    0.14270994]\n",
      "[0.8541064  0.14589362]\n",
      "[0.8615219  0.13847801]\n",
      "[0.85659665 0.14340337]\n",
      "[0.85285515 0.14714493]\n",
      "[0.8002345  0.19976544]\n",
      "[0.8486884  0.15131152]\n",
      "[0.7056758  0.29432416]\n",
      "[0.8566257  0.14337432]\n",
      "[0.7629735  0.23702653]\n",
      "[0.8471362  0.15286377]\n",
      "[0.7881654  0.21183461]\n",
      "[0.77105206 0.22894788]\n",
      "[0.8595642  0.14043583]\n",
      "[0.8473973 0.1526027]\n",
      "[0.7411475  0.25885248]\n",
      "[0.7939658  0.20603417]\n",
      "[0.8517275 0.1482725]\n",
      "[0.78267014 0.21732983]\n",
      "[0.7479761  0.25202394]\n",
      "[0.73321813 0.2667818 ]\n",
      "[0.7741321 0.2258679]\n",
      "[0.79038066 0.20961936]\n",
      "[0.78137475 0.21862528]\n",
      "[0.7819192  0.21808082]\n",
      "[0.74286026 0.2571398 ]\n",
      "[0.7593365  0.24066351]\n",
      "[0.8487722  0.15122774]\n",
      "[0.7736112  0.22638877]\n",
      "[0.84901595 0.15098399]\n",
      "[0.85913914 0.14086086]\n",
      "[0.8487618  0.15123828]\n",
      "[0.86192346 0.13807656]\n",
      "[0.84879416 0.15120582]\n",
      "[0.8594329  0.14056718]\n",
      "[0.8522412  0.14775878]\n",
      "[0.86099356 0.13900638]\n",
      "[0.8575464  0.14245355]\n",
      "[0.8608217  0.13917823]\n",
      "[0.73925513 0.2607449 ]\n",
      "[0.8566745  0.14332557]\n",
      "[0.7693152  0.23068479]\n",
      "[0.7510898  0.24891025]\n",
      "[0.7826258  0.21737425]\n",
      "[0.86125576 0.13874425]\n",
      "[0.77444094 0.22555909]\n",
      "[0.73936945 0.2606305 ]\n",
      "[0.79769796 0.20230201]\n",
      "[0.7455496 0.2544504]\n",
      "[0.8591892  0.14081076]\n",
      "[0.856716 0.143284]\n",
      "[0.74961704 0.25038296]\n",
      "[0.8558681  0.14413187]\n",
      "[0.76879823 0.23120183]\n",
      "[0.74699384 0.25300613]\n",
      "[0.8606901  0.13930982]\n",
      "[0.78602743 0.21397261]\n",
      "[0.75682    0.24318005]\n",
      "[0.8522377  0.14776231]\n",
      "[0.7577885  0.24221155]\n",
      "[0.73163474 0.26836526]\n",
      "[0.8006293  0.19937071]\n",
      "[0.8511829 0.1488172]\n",
      "[0.7613399  0.23866013]\n",
      "[0.75881124 0.24118875]\n",
      "[0.850847   0.14915295]\n",
      "[0.7802619  0.21973814]\n",
      "[0.7780431  0.22195688]\n",
      "[0.7975782  0.20242174]\n",
      "[0.85578364 0.14421634]\n",
      "[0.78057384 0.21942616]\n",
      "[0.8489616  0.15103841]\n",
      "[0.85984665 0.14015333]\n",
      "[0.7478183  0.25218174]\n",
      "[0.85949636 0.14050366]\n",
      "[0.79014635 0.20985363]\n",
      "[0.75749755 0.24250245]\n",
      "[0.730462   0.26953802]\n",
      "[0.75693256 0.24306744]\n",
      "[0.8487151  0.15128483]\n",
      "[0.8087889  0.19121106]\n",
      "[0.7649337 0.2350663]\n",
      "[0.7555342 0.2444659]\n",
      "[0.76440334 0.23559667]\n",
      "[0.84866834 0.15133168]\n",
      "[0.7808167  0.21918331]\n",
      "[0.84897316 0.15102679]\n",
      "[0.7597061  0.24029386]\n",
      "[0.8600679 0.1399321]\n",
      "[0.78645724 0.21354274]\n",
      "[0.85627365 0.14372633]\n",
      "[0.8494487  0.15055136]\n",
      "[0.76123923 0.23876077]\n",
      "[0.8473224  0.15267763]\n",
      "[0.8565446  0.14345543]\n",
      "[0.7728609  0.22713913]\n",
      "[0.7729947  0.22700526]\n",
      "[0.7605152  0.23948485]\n",
      "[0.73707646 0.2629235 ]\n",
      "[0.80165994 0.19834006]\n",
      "[0.7837874 0.2162126]\n",
      "[0.8602116 0.1397884]\n",
      "[0.7194091 0.2805909]\n",
      "[0.7451414  0.25485858]\n",
      "[0.857383   0.14261702]\n",
      "[0.75801766 0.24198228]\n",
      "[0.7998346  0.20016536]\n",
      "[0.7414896  0.25851038]\n",
      "[0.7496918  0.25030822]\n",
      "[0.76298714 0.23701283]\n",
      "[0.7854908  0.21450922]\n",
      "[0.8619419  0.13805817]\n",
      "[0.7676792  0.23232077]\n",
      "[0.79699814 0.20300183]\n",
      "[0.8514424  0.14855756]\n",
      "[0.7408949  0.25910503]\n",
      "[0.78338045 0.21661954]\n",
      "[0.8243064  0.17569353]\n",
      "[0.82963395 0.170366  ]\n",
      "[0.7716326 0.2283674]\n",
      "[0.7836027 0.2163973]\n",
      "[0.74854684 0.25145316]\n",
      "[0.7507361  0.24926391]\n",
      "[0.8480631  0.15193689]\n",
      "[0.7588656  0.24113443]\n",
      "[0.7769787  0.22302136]\n",
      "[0.7623438  0.23765619]\n",
      "[0.85052514 0.1494748 ]\n",
      "[0.8592642  0.14073582]\n",
      "[0.85488665 0.14511333]\n",
      "[0.78401685 0.21598314]\n",
      "[0.8018537  0.19814624]\n",
      "[0.8517845  0.14821552]\n",
      "[0.8598514 0.1401486]\n",
      "[0.7499592 0.2500409]\n",
      "[0.7697431  0.23025692]\n",
      "[0.76696265 0.2330374 ]\n",
      "[0.7580386  0.24196137]\n",
      "[0.7676471  0.23235287]\n",
      "[0.7570581  0.24294187]\n",
      "[0.8472929  0.15270713]\n",
      "[0.7416028  0.25839722]\n",
      "[0.75250673 0.24749325]\n",
      "[0.7543453  0.24565466]\n",
      "[0.7553665  0.24463353]\n",
      "[0.79320014 0.20679982]\n",
      "[0.7727547  0.22724532]\n",
      "[0.85369354 0.14630648]\n",
      "[0.8533736  0.14662635]\n",
      "[0.8619714  0.13802859]\n",
      "[0.74063796 0.25936195]\n",
      "[0.8542644  0.14573564]\n",
      "[0.8559802  0.14401974]\n",
      "[0.8487165  0.15128352]\n",
      "[0.7906579 0.2093421]\n",
      "[0.75074834 0.24925172]\n",
      "[0.7286265 0.2713735]\n",
      "[0.7858554 0.2141446]\n",
      "[0.85174257 0.14825743]\n",
      "[0.8579991 0.1420009]\n",
      "[0.7838852  0.21611474]\n",
      "[0.8525872  0.14741278]\n",
      "[0.8562448  0.14375517]\n",
      "[0.85222447 0.14777559]\n",
      "[0.7530089  0.24699108]\n",
      "[0.7727001  0.22729997]\n",
      "[0.85274994 0.14725001]\n",
      "[0.74144363 0.25855637]\n",
      "[0.86033994 0.13966006]\n",
      "[0.85638124 0.14361872]\n",
      "[0.78558666 0.21441339]\n",
      "[0.7457495  0.25425047]\n",
      "[0.7421813  0.25781873]\n",
      "[0.7728408 0.2271592]\n",
      "[0.7496855  0.25031444]\n",
      "[0.8486112  0.15138882]\n",
      "[0.78682125 0.21317877]\n",
      "[0.7422421  0.25775784]\n",
      "[0.7640004  0.23599954]\n",
      "[0.75702626 0.24297373]\n",
      "[0.8550192  0.14498083]\n",
      "[0.85904837 0.14095162]\n",
      "[0.8539379  0.14606202]\n",
      "[0.85264003 0.14735991]\n",
      "[0.8538827  0.14611731]\n",
      "[0.77969974 0.22030026]\n",
      "[0.7925048  0.20749523]\n",
      "[0.78356636 0.2164337 ]\n",
      "[0.80553114 0.19446889]\n",
      "[0.8589414  0.14105856]\n",
      "[0.77107364 0.22892639]\n",
      "[0.86078626 0.13921373]\n",
      "[0.77358764 0.22641236]\n",
      "[0.7905667  0.20943335]\n",
      "[0.7839657  0.21603431]\n",
      "[0.8532588 0.1467412]\n",
      "[0.8588401  0.14115995]\n",
      "[0.8064279  0.19357215]\n",
      "[0.7307755  0.26922455]\n",
      "[0.78738654 0.21261354]\n",
      "[0.7897087  0.21029125]\n",
      "[0.78818774 0.21181224]\n",
      "[0.85315704 0.14684296]\n",
      "[0.77953607 0.22046387]\n",
      "[0.85403776 0.14596222]\n",
      "[0.7759236  0.22407633]\n",
      "[0.862139   0.13786106]\n",
      "[0.8507704  0.14922959]\n",
      "[0.8526102  0.14738983]\n",
      "[0.85525334 0.14474662]\n",
      "[0.79372966 0.20627038]\n",
      "[0.8524633 0.1475367]\n",
      "[0.7724093 0.2275907]\n",
      "[0.76385504 0.23614493]\n",
      "[0.84864837 0.15135168]\n",
      "[0.8013661  0.19863388]\n",
      "[0.7929384  0.20706157]\n",
      "[0.74816716 0.25183284]\n",
      "[0.7423147  0.25768533]\n",
      "[0.7610325 0.2389675]\n",
      "[0.8537415 0.1462585]\n",
      "[0.8527127  0.14728735]\n",
      "[0.77160406 0.22839591]\n",
      "[0.84840786 0.15159215]\n",
      "[0.7877553  0.21224466]\n",
      "[0.84915006 0.15085   ]\n",
      "[0.7788001  0.22119996]\n",
      "[0.766098   0.23390196]\n",
      "[0.86184394 0.13815612]\n",
      "[0.73479104 0.26520902]\n",
      "[0.8467752 0.1532248]\n",
      "[0.7561326  0.24386735]\n",
      "[0.7881517 0.2118483]\n",
      "[0.85323006 0.14676996]\n",
      "[0.7734792  0.22652078]\n",
      "[0.85084    0.14916007]\n",
      "[0.86104095 0.13895907]\n",
      "[0.8499589  0.15004115]\n",
      "[0.7811185  0.21888156]\n",
      "[0.7570724 0.2429276]\n",
      "[0.7965408  0.20345914]\n",
      "[9.9999988e-01 7.6198276e-08]\n",
      "[0.8556811  0.14431888]\n",
      "[0.84687907 0.15312098]\n",
      "[0.8603542 0.1396458]\n",
      "[0.7590892  0.24091077]\n",
      "[0.7600942  0.23990583]\n",
      "[0.8528954  0.14710465]\n",
      "[0.8611886  0.13881145]\n",
      "[0.8586863  0.14131363]\n",
      "[0.762085 0.237915]\n",
      "[0.8563365 0.1436635]\n",
      "[0.7497557 0.2502443]\n",
      "[0.85620826 0.14379178]\n",
      "[0.84985614 0.1501438 ]\n",
      "[0.76879466 0.23120539]\n",
      "[0.7376411  0.26235893]\n",
      "[0.8553989  0.14460106]\n",
      "[0.7837369  0.21626312]\n",
      "[0.7724594  0.22754055]\n",
      "[0.8596352 0.1403648]\n",
      "[0.8580994  0.14190058]\n",
      "[0.79610455 0.20389546]\n",
      "[0.7508527  0.24914733]\n",
      "[0.8546955  0.14530453]\n",
      "[0.76162916 0.23837085]\n",
      "[0.770217 0.229783]\n",
      "[0.86169565 0.13830435]\n",
      "[0.8555575  0.14444247]\n",
      "[0.7874968  0.21250325]\n",
      "[0.7747319  0.22526805]\n",
      "[0.85341007 0.14658998]\n",
      "[0.7606775  0.23932245]\n",
      "[0.85084605 0.14915392]\n",
      "[0.7637774  0.23622262]\n",
      "[0.85424966 0.1457503 ]\n",
      "[0.75516814 0.24483185]\n",
      "[0.7867639  0.21323611]\n",
      "[0.7321503 0.2678497]\n",
      "[0.8522809  0.14771914]\n",
      "[0.7677401  0.23225993]\n",
      "[0.8588517  0.14114831]\n",
      "[0.7678614 0.2321386]\n",
      "[0.79947823 0.20052171]\n",
      "[0.76097333 0.23902667]\n",
      "[0.7675726  0.23242745]\n",
      "[0.85639393 0.14360611]\n",
      "[0.7479118 0.2520882]\n",
      "[0.77272004 0.22727993]\n",
      "[0.7571755  0.24282455]\n",
      "[0.85148317 0.1485168 ]\n",
      "[0.7327298 0.2672702]\n",
      "[0.8600405  0.13995947]\n",
      "[0.8496877 0.1503123]\n",
      "[0.7893858  0.21061422]\n",
      "[0.8529697 0.1470303]\n",
      "[0.77416605 0.22583398]\n",
      "[0.8608763 0.1391237]\n",
      "[0.7457275  0.25427252]\n",
      "[0.7984015  0.20159847]\n",
      "[0.8499988  0.15000126]\n",
      "[0.8585278  0.14147227]\n",
      "[0.8483042  0.15169577]\n",
      "[0.85054904 0.14945099]\n",
      "[0.7481544  0.25184554]\n",
      "[0.85421854 0.14578143]\n",
      "[0.73283714 0.26716283]\n",
      "[0.7780067  0.22199334]\n",
      "[0.77736986 0.22263017]\n",
      "[0.8501487  0.14985134]\n",
      "[0.8494338 0.1505662]\n",
      "[0.8571913  0.14280869]\n",
      "[0.72817576 0.27182424]\n",
      "[0.8533032 0.1466968]\n",
      "[0.8570717 0.1429283]\n",
      "[0.857256   0.14274408]\n",
      "[0.8048408  0.19515917]\n",
      "[0.77220017 0.22779986]\n",
      "[0.8501619  0.14983808]\n",
      "[0.7644493  0.23555075]\n",
      "[0.7539187 0.2460812]\n",
      "[0.7864783 0.2135217]\n",
      "[0.7467844 0.2532156]\n",
      "[0.7700877 0.2299123]\n",
      "[0.774616   0.22538397]\n",
      "[0.79172057 0.20827946]\n",
      "[0.75653076 0.24346927]\n",
      "[0.855086  0.1449139]\n",
      "[0.7722892  0.22771074]\n",
      "[0.85799766 0.14200231]\n",
      "[0.7720044  0.22799557]\n",
      "[0.7729299  0.22707008]\n",
      "[0.8005782  0.19942182]\n",
      "[0.85979366 0.14020634]\n",
      "[0.7517826 0.2482174]\n",
      "[0.7358461  0.26415393]\n",
      "[0.85467213 0.14532788]\n",
      "[0.8509978  0.14900218]\n",
      "[0.85723424 0.14276579]\n",
      "[0.8090731  0.19092691]\n",
      "[0.78828454 0.21171546]\n",
      "[0.85588646 0.14411353]\n",
      "[0.759725   0.24027504]\n",
      "[0.77846146 0.22153857]\n",
      "[0.8569549  0.14304507]\n",
      "[0.74644476 0.25355527]\n",
      "[0.76736    0.23264006]\n",
      "[0.773986 0.226014]\n",
      "[0.7493043 0.2506957]\n",
      "[0.8578928  0.14210722]\n",
      "[0.75468916 0.24531081]\n",
      "[0.83366996 0.16633002]\n",
      "[0.85796916 0.14203088]\n",
      "[0.7758875  0.22411247]\n",
      "[0.70637774 0.2936223 ]\n",
      "[0.85211045 0.14788958]\n",
      "[0.8575559  0.14244407]\n",
      "[0.74213123 0.25786874]\n",
      "[0.85180163 0.1481984 ]\n",
      "[0.8466163  0.15338369]\n",
      "[0.8555229  0.14447716]\n",
      "[0.7708845  0.22911547]\n",
      "[0.74721867 0.25278133]\n",
      "[0.84694576 0.15305422]\n",
      "[0.84696496 0.15303501]\n",
      "[0.85534656 0.14465345]\n",
      "[0.859276   0.14072399]\n",
      "[0.7756457  0.22435433]\n",
      "[0.7763531  0.22364688]\n",
      "[0.7572144  0.24278556]\n",
      "[0.72600496 0.27399507]\n",
      "[0.76685256 0.23314737]\n",
      "[0.85249776 0.14750218]\n",
      "[0.84777206 0.15222795]\n",
      "[0.7481311  0.25186887]\n",
      "[0.76812047 0.23187952]\n",
      "[0.75551987 0.24448012]\n",
      "[0.74068123 0.25931877]\n",
      "[0.74932766 0.25067234]\n",
      "[0.8501744  0.14982565]\n",
      "[0.77316296 0.22683702]\n",
      "[0.8498952  0.15010487]\n",
      "[0.8496468  0.15035321]\n",
      "[0.7769115  0.22308849]\n",
      "[0.8609147  0.13908538]\n",
      "[0.78963095 0.21036904]\n",
      "[0.8508959  0.14910415]\n",
      "[0.73937166 0.2606283 ]\n",
      "[0.7634462  0.23655374]\n",
      "[0.7658731  0.23412688]\n",
      "[0.85770595 0.142294  ]\n",
      "[0.7433934  0.25660664]\n",
      "[0.7632495  0.23675051]\n",
      "[0.8518181  0.14818197]\n",
      "[0.8552744  0.14472568]\n",
      "[0.783199 0.216801]\n",
      "[0.77190775 0.22809221]\n",
      "[0.80931795 0.19068205]\n",
      "[0.7478182 0.2521818]\n",
      "[0.7241168 0.2758832]\n",
      "[0.85430086 0.14569913]\n",
      "[0.7996996  0.20030041]\n",
      "[0.77049524 0.22950482]\n",
      "[0.75210613 0.2478939 ]\n",
      "[0.7856748  0.21432525]\n",
      "[0.7551475 0.2448525]\n",
      "[0.8581187  0.14188129]\n",
      "[0.78135335 0.21864665]\n",
      "[0.7960287  0.20397139]\n",
      "[0.76060253 0.23939744]\n",
      "[0.75889564 0.24110438]\n",
      "[0.85268974 0.14731027]\n",
      "[0.78033376 0.21966632]\n",
      "[0.7543233  0.24567671]\n",
      "[0.7433895  0.25661048]\n",
      "[0.7829512 0.2170488]\n",
      "[0.76175183 0.23824811]\n",
      "[0.86128896 0.13871105]\n",
      "[0.74619263 0.25380737]\n",
      "[0.78791136 0.21208861]\n",
      "[0.84797215 0.1520278 ]\n",
      "[0.7248647  0.27513525]\n",
      "[0.8620811  0.13791883]\n",
      "[0.8592389  0.14076105]\n",
      "[0.7603164  0.23968358]\n",
      "[0.7983343 0.2016657]\n",
      "[0.79033697 0.2096631 ]\n",
      "[0.78059393 0.21940611]\n",
      "[0.8599013  0.14009872]\n",
      "[0.7929417  0.20705827]\n",
      "[0.7400626  0.25993747]\n",
      "[0.85621    0.14378999]\n",
      "[0.8593032  0.14069678]\n",
      "[0.7401875 0.2598125]\n",
      "[0.8507182 0.1492818]\n",
      "[0.8545856  0.14541437]\n",
      "[0.7706008  0.22939914]\n",
      "[0.73572975 0.26427022]\n",
      "[0.77480716 0.22519279]\n",
      "[0.77273864 0.22726133]\n",
      "[0.85439783 0.14560214]\n",
      "[0.85433084 0.14566919]\n",
      "[0.8560699  0.14393006]\n",
      "[0.7603877  0.23961228]\n",
      "[0.7275632  0.27243677]\n",
      "[0.75422263 0.24577738]\n",
      "[0.8512252  0.14877479]\n",
      "[0.7802612  0.21973878]\n",
      "[0.85066706 0.14933291]\n",
      "[0.76099867 0.23900133]\n",
      "[0.85078025 0.1492198 ]\n",
      "[0.80742943 0.19257061]\n",
      "[0.7552417 0.2447583]\n",
      "[0.846839   0.15316099]\n",
      "[0.7703377  0.22966231]\n",
      "[0.75388634 0.2461136 ]\n",
      "[0.7775501  0.22244985]\n",
      "[0.7540129  0.24598712]\n",
      "[0.7917137  0.20828629]\n",
      "[0.8564631  0.14353688]\n",
      "[0.75785017 0.24214981]\n",
      "[0.7602075  0.23979251]\n",
      "[0.8562221  0.14377792]\n",
      "[0.8084236 0.1915764]\n",
      "[0.7654637  0.23453635]\n",
      "[0.772925  0.2270749]\n",
      "[0.8035006 0.1964994]\n",
      "[0.7757831  0.22421691]\n",
      "[0.784437   0.21556301]\n",
      "[0.7859269  0.21407308]\n",
      "[0.7909862  0.20901377]\n",
      "[0.8598686  0.14013138]\n",
      "[0.7885033  0.21149671]\n",
      "[0.7748006  0.22519945]\n",
      "[0.76815164 0.23184827]\n",
      "[0.7635698  0.23643023]\n",
      "[0.77246857 0.22753137]\n",
      "[0.7797838  0.22021623]\n",
      "[0.85358393 0.14641613]\n",
      "[0.726501   0.27349904]\n",
      "[0.74263 0.25737]\n",
      "[0.7834549  0.21654509]\n",
      "[0.8151895  0.18481049]\n",
      "[0.8485522  0.15144779]\n",
      "[0.7297998 0.2702002]\n",
      "[0.8126153  0.18738477]\n",
      "[0.8572062  0.14279374]\n",
      "[0.84902644 0.15097354]\n",
      "[0.7286667  0.27133334]\n",
      "[0.7685816  0.23141839]\n",
      "[0.7540101  0.24598989]\n",
      "[0.85582453 0.14417545]\n",
      "[0.77199733 0.22800271]\n",
      "[0.7430599 0.2569401]\n",
      "[0.8493275  0.15067248]\n",
      "[0.76453996 0.23546007]\n",
      "[0.7469029  0.25309718]\n",
      "[0.78369975 0.21630017]\n",
      "[0.75850445 0.24149553]\n",
      "[0.85238266 0.1476173 ]\n",
      "[0.76205117 0.23794888]\n",
      "[0.7906496  0.20935038]\n",
      "[0.85543174 0.14456831]\n",
      "[0.74282706 0.2571729 ]\n",
      "[0.76501346 0.2349866 ]\n",
      "[0.7684395  0.23156053]\n",
      "[0.85939455 0.1406054 ]\n",
      "[0.8571945  0.14280553]\n",
      "[0.7504041  0.24959584]\n",
      "[0.77048534 0.22951475]\n",
      "[0.7632493  0.23675074]\n",
      "[0.85386544 0.14613461]\n",
      "[0.7901067  0.20989332]\n",
      "[0.84858054 0.15141946]\n",
      "[0.751199   0.24880101]\n",
      "[0.8501479  0.14985217]\n",
      "[0.8504103  0.14958969]\n",
      "[0.86226875 0.13773125]\n",
      "[0.7895154  0.21048464]\n",
      "[0.77057266 0.22942732]\n",
      "[0.85102165 0.14897835]\n",
      "[0.769694   0.23030604]\n",
      "[0.76394904 0.23605102]\n",
      "[0.7809332  0.21906677]\n",
      "[0.7652472  0.23475277]\n",
      "[0.85499305 0.14500692]\n",
      "[0.8106753 0.1893247]\n",
      "[0.85042685 0.14957313]\n",
      "[0.7481085 0.2518915]\n",
      "[0.72702426 0.27297577]\n",
      "[0.86166 0.13834]\n",
      "[0.74989635 0.25010365]\n",
      "[0.85803884 0.14196122]\n",
      "[0.77880657 0.22119342]\n",
      "[0.7600386  0.23996133]\n",
      "[0.8532807 0.1467193]\n",
      "[0.8614763 0.1385237]\n",
      "[0.73836    0.26163998]\n",
      "[0.81468034 0.18531962]\n",
      "[0.74897516 0.2510248 ]\n",
      "[0.78313833 0.2168617 ]\n",
      "[0.7915493  0.20845068]\n",
      "[0.7538216  0.24617837]\n",
      "[0.8524601 0.1475399]\n",
      "[0.75919735 0.2408026 ]\n",
      "[0.76852065 0.23147933]\n",
      "[0.79974526 0.20025477]\n",
      "[0.8563838  0.14361623]\n",
      "[0.8537589 0.1462411]\n",
      "[0.7531267  0.24687332]\n",
      "[0.7534324  0.24656758]\n",
      "[0.7955525  0.20444751]\n",
      "[0.8564437  0.14355631]\n",
      "[0.8538749  0.14612506]\n",
      "[0.78717166 0.21282835]\n",
      "[0.76888263 0.23111741]\n",
      "[0.741879   0.25812104]\n",
      "[0.8466069  0.15339313]\n",
      "[0.76165575 0.23834424]\n",
      "[0.77446413 0.22553594]\n",
      "[0.84891605 0.151084  ]\n",
      "[0.7749202 0.2250798]\n",
      "[0.766942   0.23305798]\n",
      "[0.8552061  0.14479391]\n",
      "[0.74599713 0.2540028 ]\n",
      "[0.853263   0.14673702]\n",
      "[0.7640797  0.23592031]\n",
      "[0.8489809  0.15101905]\n",
      "[0.85131544 0.14868453]\n",
      "[0.79083693 0.2091631 ]\n",
      "[0.8519452  0.14805478]\n",
      "[0.7511065  0.24889348]\n",
      "[0.75477195 0.24522799]\n",
      "[0.7683771  0.23162295]\n",
      "[0.75204635 0.24795367]\n",
      "[0.7837499  0.21625017]\n",
      "[0.7821819  0.21781804]\n",
      "[0.74733084 0.2526691 ]\n",
      "[0.85279185 0.14720817]\n",
      "[0.847461   0.15253897]\n",
      "[0.75244087 0.24755912]\n",
      "[0.71471906 0.28528094]\n",
      "[0.8554553  0.14454477]\n",
      "[0.7602995 0.2397005]\n",
      "[0.74970764 0.25029233]\n",
      "[0.8581893  0.14181077]\n",
      "[0.7711116  0.22888839]\n",
      "[0.7596363  0.24036375]\n",
      "[0.81269413 0.1873058 ]\n",
      "[0.76372623 0.23627375]\n",
      "[0.81782883 0.18217118]\n",
      "[0.85907316 0.14092687]\n",
      "[0.7796667  0.22033332]\n",
      "[0.8084007  0.19159937]\n",
      "[0.7378053  0.26219472]\n",
      "[0.8598345  0.14016552]\n",
      "[0.7646427 0.2353573]\n",
      "[0.85506517 0.14493482]\n",
      "[0.7042907  0.29570934]\n",
      "[0.7676794  0.23232062]\n",
      "[0.78441525 0.21558474]\n",
      "[0.77365863 0.2263414 ]\n",
      "[0.74926937 0.25073063]\n",
      "[0.7332034  0.26679662]\n",
      "[0.7727726  0.22722742]\n",
      "[0.77202445 0.22797547]\n",
      "[0.8602626 0.1397374]\n",
      "[0.8621046  0.13789544]\n",
      "[0.7690483  0.23095168]\n",
      "[0.766098   0.23390192]\n",
      "[0.73652625 0.26347378]\n",
      "[0.76161456 0.23838542]\n",
      "[0.7534347  0.24656528]\n",
      "[0.75318193 0.2468181 ]\n",
      "[0.861036   0.13896403]\n",
      "[0.7556489  0.24435115]\n",
      "[0.7788022  0.22119772]\n",
      "[0.8545352  0.14546476]\n",
      "[0.75773054 0.24226949]\n",
      "[0.7893903  0.21060963]\n",
      "[0.76043236 0.23956756]\n",
      "[0.7482975 0.2517025]\n",
      "[0.7604274  0.23957253]\n",
      "[0.77358454 0.22641544]\n",
      "[0.7744198  0.22558026]\n",
      "[0.74420416 0.25579584]\n",
      "[0.8503105  0.14968951]\n",
      "[0.8516743  0.14832567]\n",
      "[0.76994157 0.23005845]\n",
      "[0.8522995  0.14770044]\n",
      "[0.75848854 0.24151145]\n",
      "[0.7244119 0.2755881]\n",
      "[0.853892   0.14610794]\n",
      "[0.7962283  0.20377174]\n",
      "[0.766152   0.23384795]\n",
      "[0.78783625 0.21216373]\n",
      "[0.85182464 0.14817539]\n",
      "[0.77674556 0.22325449]\n",
      "[0.78571475 0.21428528]\n",
      "[0.77401716 0.22598287]\n",
      "[0.85137266 0.14862734]\n",
      "[0.75462437 0.24537566]\n",
      "[0.7680666  0.23193339]\n",
      "[0.72791237 0.27208754]\n",
      "[0.74543095 0.25456908]\n",
      "[0.850448 0.149552]\n",
      "[0.79030734 0.20969269]\n",
      "[0.85224724 0.14775279]\n",
      "[0.7616668 0.2383332]\n",
      "[0.86053693 0.13946302]\n",
      "[0.7625095  0.23749048]\n",
      "[0.8600053  0.13999471]\n",
      "[0.786807   0.21319304]\n",
      "[0.8622288  0.13777116]\n",
      "[0.8619145  0.13808545]\n",
      "[0.8524712  0.14752886]\n",
      "[0.85762054 0.14237946]\n",
      "[0.7620138  0.23798627]\n",
      "[0.79219776 0.20780225]\n",
      "[0.7792239  0.22077607]\n",
      "[0.85600793 0.1439921 ]\n",
      "[0.76571375 0.23428622]\n",
      "[0.8487279  0.15127215]\n",
      "[0.7702906  0.22970939]\n",
      "[0.84795374 0.15204623]\n",
      "[0.7410473 0.2589527]\n",
      "[0.8525823  0.14741774]\n",
      "[0.85095406 0.1490459 ]\n",
      "[0.71068794 0.28931206]\n",
      "[0.80310714 0.19689289]\n",
      "[0.807246  0.1927539]\n",
      "[0.8475559  0.15244417]\n",
      "[0.85993314 0.1400669 ]\n",
      "[0.7436505  0.25634947]\n",
      "[0.8531871  0.14681295]\n",
      "[0.757693   0.24230698]\n",
      "[0.74566746 0.2543326 ]\n",
      "[0.79409915 0.20590085]\n",
      "[0.74248284 0.25751725]\n",
      "[0.8594025  0.14059754]\n",
      "[0.85274553 0.14725442]\n",
      "[0.85092455 0.14907543]\n",
      "[0.7816954  0.21830456]\n",
      "[0.73959255 0.26040745]\n",
      "[0.7799739  0.22002608]\n",
      "[0.7837402  0.21625979]\n",
      "[0.85573894 0.14426105]\n",
      "[0.8568883  0.14311174]\n",
      "[0.79852664 0.20147331]\n",
      "[0.858006   0.14199394]\n",
      "[0.85426074 0.14573926]\n",
      "[0.76842386 0.23157611]\n",
      "[0.71317524 0.2868248 ]\n",
      "[0.7717055  0.22829445]\n",
      "[0.7512889  0.24871108]\n",
      "[0.77481914 0.22518086]\n",
      "[0.77507037 0.22492969]\n",
      "[0.7417243  0.25827575]\n",
      "[0.7681148  0.23188516]\n",
      "[0.8558473  0.14415267]\n",
      "[0.75674975 0.24325025]\n",
      "[0.74176943 0.25823063]\n",
      "[0.7425576 0.2574424]\n",
      "[0.8490029  0.15099709]\n",
      "[0.857047   0.14295305]\n",
      "[0.8603423  0.13965763]\n",
      "[0.8565291  0.14347084]\n",
      "[0.7523247  0.24767527]\n",
      "[0.8520128  0.14798716]\n",
      "[0.76161605 0.23838398]\n",
      "[0.8593807 0.1406193]\n",
      "[0.8480808  0.15191926]\n",
      "[0.8512687  0.14873132]\n",
      "[0.8575408  0.14245927]\n",
      "[0.85501426 0.14498581]\n",
      "[0.8490632 0.1509368]\n",
      "[0.7825057 0.2174943]\n",
      "[0.7493977 0.2506023]\n",
      "[0.75986207 0.24013793]\n",
      "[0.70870763 0.2912923 ]\n",
      "[0.7499656  0.25003442]\n",
      "[0.7596922  0.24030778]\n",
      "[0.77206945 0.22793052]\n",
      "[0.7589629 0.241037 ]\n",
      "[0.7538636  0.24613643]\n",
      "[0.853624   0.14637607]\n",
      "[0.8494594  0.15054058]\n",
      "[0.7826289  0.21737103]\n",
      "[0.8570215  0.14297849]\n",
      "[0.7453169 0.2546831]\n",
      "[0.7785912  0.22140875]\n",
      "[0.85555786 0.14444219]\n",
      "[0.7757253  0.22427467]\n",
      "[0.74034005 0.25965992]\n",
      "[0.85105664 0.14894341]\n",
      "[0.76936686 0.23063312]\n",
      "[0.86196774 0.13803223]\n",
      "[0.8568321  0.14316788]\n",
      "[0.75663024 0.2433698 ]\n",
      "[0.7705156  0.22948442]\n",
      "[0.78754395 0.21245603]\n",
      "[0.7506039  0.24939607]\n",
      "[0.76573193 0.23426807]\n",
      "[0.764      0.23599996]\n",
      "[0.76571596 0.23428404]\n",
      "[0.78372645 0.21627362]\n",
      "[0.7819748  0.21802524]\n",
      "[0.7011565 0.2988435]\n",
      "[0.78268254 0.21731745]\n",
      "[0.8513552  0.14864479]\n",
      "[0.8485387  0.15146121]\n",
      "[0.85860705 0.14139296]\n",
      "[0.7582842  0.24171576]\n",
      "[0.78759897 0.21240105]\n",
      "[0.76847434 0.23152569]\n",
      "[0.84992653 0.15007347]\n",
      "[0.70106834 0.29893166]\n",
      "[0.8581885  0.14181149]\n",
      "[0.85945946 0.14054056]\n",
      "[0.8573992 0.1426008]\n",
      "[0.85971916 0.14028083]\n",
      "[0.79679227 0.20320775]\n",
      "[0.8571604 0.1428396]\n",
      "[0.76578254 0.23421744]\n",
      "[0.7889519  0.21104811]\n",
      "[0.8497941  0.15020587]\n",
      "[0.7418702  0.25812975]\n",
      "[0.7532193  0.24678072]\n",
      "[0.77035195 0.22964807]\n",
      "[0.84714484 0.15285519]\n",
      "[0.85362685 0.1463732 ]\n",
      "[0.85788053 0.14211945]\n",
      "[0.8486984 0.1513016]\n",
      "[0.7800345  0.21996555]\n",
      "[0.852927   0.14707303]\n",
      "[0.74545574 0.25454432]\n",
      "[0.7788867  0.22111332]\n",
      "[0.75453544 0.24546453]\n",
      "[0.8545693  0.14543071]\n",
      "[0.8600667  0.13993333]\n",
      "[0.86105865 0.13894133]\n",
      "[0.7861381  0.21386188]\n",
      "[0.86073273 0.13926725]\n",
      "[0.8502019  0.14979811]\n",
      "[0.81623125 0.18376876]\n",
      "[0.7528423  0.24715768]\n",
      "[0.8545669  0.14543308]\n",
      "[0.78216136 0.21783862]\n",
      "[0.78082526 0.21917471]\n",
      "[0.7798266  0.22017342]\n",
      "[0.73067856 0.2693214 ]\n",
      "[0.7457434  0.25425664]\n",
      "[0.8524457  0.14755425]\n",
      "[0.73438317 0.26561683]\n",
      "[0.76690155 0.23309843]\n",
      "[0.7528867  0.24711333]\n",
      "[0.75673914 0.24326088]\n",
      "[0.7875543  0.21244569]\n",
      "[0.77889943 0.22110055]\n",
      "[0.759867   0.24013305]\n",
      "[0.85934114 0.1406589 ]\n",
      "[0.85695523 0.14304481]\n",
      "[0.76722    0.23277996]\n",
      "[0.8512964  0.14870353]\n",
      "[0.738732   0.26126802]\n",
      "[0.8482038  0.15179628]\n",
      "[0.85620457 0.14379539]\n",
      "[0.75696874 0.24303123]\n",
      "[0.76473147 0.23526852]\n",
      "[0.77032614 0.22967394]\n",
      "[0.8498639  0.15013611]\n",
      "[0.78255844 0.21744156]\n",
      "[0.85180414 0.14819585]\n",
      "[0.8533018  0.14669819]\n",
      "[0.75463414 0.24536593]\n",
      "[0.7779131  0.22208692]\n",
      "[0.8519936  0.14800642]\n",
      "[0.72921175 0.2707882 ]\n",
      "[0.851886 0.148114]\n",
      "[0.74669254 0.25330746]\n",
      "[0.7847286  0.21527143]\n",
      "[0.85463375 0.14536625]\n",
      "[0.8506891  0.14931093]\n",
      "[0.8018827 0.1981173]\n",
      "[0.8494779 0.1505221]\n",
      "[0.78204566 0.21795435]\n",
      "[0.78320235 0.21679758]\n",
      "[0.7633727  0.23662733]\n",
      "[0.8046245  0.19537552]\n",
      "[0.84911305 0.15088691]\n",
      "[0.77220064 0.22779937]\n",
      "[0.8227658  0.17723411]\n",
      "[0.7868486  0.21315141]\n",
      "[0.7690427  0.23095731]\n",
      "[0.78956306 0.21043691]\n",
      "[0.7544394  0.24556062]\n",
      "[0.8620339  0.13796607]\n",
      "[0.75292975 0.24707024]\n",
      "[0.746169   0.25383094]\n",
      "[0.84690034 0.15309969]\n",
      "[0.86174494 0.13825502]\n",
      "[0.77826303 0.2217369 ]\n",
      "[0.7526653 0.2473347]\n",
      "[0.7677354  0.23226456]\n",
      "[0.85336673 0.14663322]\n",
      "[0.75504315 0.24495688]\n",
      "[0.7447511  0.25524893]\n",
      "[0.79049885 0.20950113]\n",
      "[0.85104436 0.14895563]\n",
      "[0.729075 0.270925]\n",
      "[0.76367736 0.23632258]\n",
      "[0.7712405  0.22875951]\n",
      "[0.80326164 0.1967384 ]\n",
      "[0.76518524 0.23481478]\n",
      "[0.85491544 0.14508456]\n",
      "[0.8474258  0.15257415]\n",
      "[0.77827007 0.22172992]\n",
      "[0.79257864 0.20742139]\n",
      "[0.8601188  0.13988113]\n",
      "[0.84982264 0.15017731]\n",
      "[0.79197884 0.20802122]\n",
      "[0.78058535 0.21941468]\n",
      "[0.8528697  0.14713036]\n",
      "[0.85111904 0.14888093]\n",
      "[0.7407514  0.25924864]\n",
      "[0.8599844  0.14001551]\n",
      "[0.7481 0.2519]\n",
      "[0.7620264  0.23797359]\n",
      "[0.80834806 0.19165191]\n",
      "[0.7544928  0.24550721]\n",
      "[0.77060676 0.22939323]\n",
      "[0.7953998  0.20460024]\n",
      "[0.77671534 0.22328462]\n",
      "[0.8504813  0.14951876]\n",
      "[0.8475355  0.15246455]\n",
      "[0.84995115 0.15004893]\n",
      "[0.8570745 0.1429255]\n",
      "[0.78732973 0.21267024]\n",
      "[0.8575574 0.1424426]\n",
      "[0.7541489  0.24585105]\n",
      "[0.76100755 0.23899251]\n",
      "[0.82282364 0.17717636]\n",
      "[0.7878925  0.21210748]\n",
      "[0.85445267 0.14554735]\n",
      "[0.8612005  0.13879953]\n",
      "[0.8495574  0.15044262]\n",
      "[0.8524368  0.14756325]\n",
      "[0.7519075  0.24809252]\n",
      "[0.8496549  0.15034507]\n",
      "[0.8021864  0.19781353]\n",
      "[0.84739715 0.15260285]\n",
      "[0.7962118  0.20378818]\n",
      "[0.76089674 0.23910327]\n",
      "[0.7543787  0.24562131]\n",
      "[0.85802585 0.14197414]\n",
      "[0.74878895 0.251211  ]\n",
      "[0.8605108  0.13948916]\n",
      "[0.85638666 0.14361331]\n",
      "[0.7544176 0.2455824]\n",
      "[0.85231626 0.14768375]\n",
      "[0.74669355 0.25330642]\n",
      "[0.7568193  0.24318063]\n",
      "[0.76821864 0.23178132]\n",
      "[0.76322913 0.23677085]\n",
      "[0.7712305  0.22876948]\n",
      "[0.8473515  0.15264852]\n",
      "[0.76863253 0.23136744]\n",
      "[0.7378271 0.2621729]\n",
      "[0.84779674 0.1522033 ]\n",
      "[0.84726536 0.15273465]\n",
      "[0.7512532  0.24874681]\n",
      "[0.7942167 0.2057833]\n",
      "[0.73088944 0.26911053]\n",
      "[0.7678275 0.2321725]\n",
      "[0.76708835 0.23291169]\n",
      "[0.7501116  0.24988844]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashishsingh/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2_rounded = model2.predict_classes(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(y, axis=None, out=None) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model2.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_classes,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_classes, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2376,    0],\n",
       "       [ 624,    0]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916666666666666"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_classes,predictions2_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2372,    4],\n",
       "       [ 621,    3]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_classes, predictions2_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
