{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ashishsingh/AIML/Assignments/Introduction to Neural Networks and Deep Learning_R7_INN_Project2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() #to get current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "filename = 'SVHN_single_grey1.h5'\n",
    "dataframe = h5py.File(filename, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>\n",
      "X_test\n"
     ]
    }
   ],
   "source": [
    "# # List all groups\n",
    "print(\"Keys: %s\" % dataframe.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetnames = [n for n in dataframe.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "X_train\n",
      "X_val\n",
      "y_test\n",
      "y_train\n",
      "y_val\n"
     ]
    }
   ],
   "source": [
    "for n in datasetnames:\n",
    "    print(n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = dataFrame['X_test']\n",
    "x_train = dataFrame['X_train']\n",
    "x_val = dataFrame['X_val']\n",
    "y_test = dataFrame['y_test']\n",
    "y_train = dataFrame['y_train']\n",
    "y_val = dataFrame['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataframe.keys():\n",
    "    print(dataframe[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"X_train\": shape (42000, 32, 32), type \"<f4\">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataframe['X_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataframe['X_train'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 33.0704,  30.2601,  26.852 , ...,  71.4471,  58.2204,  42.9939],\n",
       "       [ 25.2283,  25.5533,  29.9765, ..., 113.0209, 103.3639,  84.2949],\n",
       "       [ 26.2775,  22.6137,  40.4763, ..., 113.3028, 121.775 , 115.4228],\n",
       "       ...,\n",
       "       [ 28.5502,  36.212 ,  45.0801, ...,  24.1359,  25.0927,  26.0603],\n",
       "       [ 38.4352,  26.4733,  23.2717, ...,  28.1094,  29.4683,  30.0661],\n",
       "       [ 50.2984,  26.0773,  24.0389, ...,  49.6682,  50.853 ,  53.0377]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataframe['X_train'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement and apply an optimal k-Nearest Neighbor (kNN) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv2.resize(list(dataframe['X_train'])[0], (32,32)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening from 3D to 2D\n",
    "X_train = np.reshape(x_train,(42000,32*32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNH = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNH.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "# Change the dimension from 3D -> 2D\n",
    "X_test = np.reshape(x_test,(18000,32*32))\n",
    "prediction = NNH.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "print(\"Confusion Matrix:\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report\n",
    "cr=metrics.classification_report(y_test,prediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data from 2D to 1D -> 32X32 to 1024\n",
    "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(150, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change train and test labels into one-hot vectors\n",
    "trainY = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "features_val_arr = np.array(x_test)\n",
    "model.fit(x_train,trainY,          \n",
    "          validation_data=(features_val_arr, testY),\n",
    "          epochs=75,\n",
    "          batch_size=150,validation_split = 0.01,\n",
    "         shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "evaluate = model.evaluate(x_text, testY)\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "y_predict=model.predict_classes(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=metrics.classification_report(y_test,y_predict)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train and evaluate a k-NN classifer on the histogram\n",
    "# # representations\n",
    "# print(\"[INFO] evaluating accuracy...\")\n",
    "\n",
    "# NNH.fit(X_train_new, y_train)\n",
    "# acc = NNH.score(X_train_new, y_train)\n",
    "# print(\"[INFO]  accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classification metrics report\n",
    "# sklearn.metrics.classification_report(y_test, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K fold\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # creating odd list of K for KNN\n",
    "# myList = list(range(1,50))\n",
    "\n",
    "\n",
    "# # empty list that will hold cv scores\n",
    "# cv_scores = []\n",
    "# k_neighbors = []\n",
    "\n",
    "# # perform 10-fold cross validation\n",
    "# for k in myList:\n",
    "#     knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#     scores = cross_val_score(knn, X_train_new, y_train, cv=10, scoring='accuracy')\n",
    "#     cv_scores.append(scores.mean())\n",
    "#     k_neighbors.append(k)\n",
    "\n",
    "\n",
    "# MSE = [1 - x for x in cv_scores]\n",
    "# min(MSE)\n",
    "# MSE.index(min(MSE))\n",
    "# best_k = myList[MSE.index(min(MSE))]\n",
    "# print (\"The optimal number of neighbors is %d\" % best_k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
